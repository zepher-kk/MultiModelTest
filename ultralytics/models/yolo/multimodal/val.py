# Ultralytics YOLO ğŸš€, AGPL-3.0 license

from ultralytics.models.yolo.detect.val import DetectionValidator
from ultralytics.data.dataset import YOLOMultiModalImageDataset
from ultralytics.data import build_yolo_dataset
from ultralytics.utils import LOGGER, colorstr
from ultralytics.utils.torch_utils import de_parallel
import torch
from ultralytics.utils.checks import check_imgsz
from ultralytics.nn.autobackend import AutoBackend
from ultralytics.utils import TQDM, callbacks, emojis
from ultralytics.utils.ops import Profile
from ultralytics.data.utils import check_det_dataset
from ultralytics.utils.torch_utils import select_device, smart_inference_mode
import json


class MultiModalDetectionValidator(DetectionValidator):
    """
    å¤šæ¨¡æ€æ£€æµ‹éªŒè¯å™¨ï¼Œå¤„ç†RGB+Xè¾“å…¥çš„éªŒè¯å’Œè¯„ä¼°ã€‚
    
    è¿™ä¸ªç±»ç»§æ‰¿DetectionValidatorï¼Œé‡å†™å…³é”®æ–¹æ³•ä»¥æ”¯æŒå¤šæ¨¡æ€æ•°æ®é›†å’Œ6é€šé“è¾“å…¥ã€‚
    ä¸MultiModalDetectionTrainerä¿æŒä¸€è‡´çš„å¤šæ¨¡æ€æ•°æ®å¤„ç†èƒ½åŠ›ã€‚
    """

    def __init__(self, dataloader=None, save_dir=None, pbar=None, args=None, _callbacks=None):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€æ£€æµ‹éªŒè¯å™¨ã€‚

        Args:
            dataloader: æ•°æ®åŠ è½½å™¨
            save_dir: ä¿å­˜ç›®å½•
            pbar: è¿›åº¦æ¡ï¼ˆå½“å‰é¡¹ç›®ä¸æ”¯æŒï¼Œå¿½ç•¥ï¼‰
            args: å‚æ•°é…ç½®
            _callbacks: å›è°ƒå‡½æ•°
        """
        # é€‚é…å½“å‰é¡¹ç›®çš„DetectionValidator.__init__ç­¾åï¼ˆä¸åŒ…å«pbarå‚æ•°ï¼‰
        super().__init__(dataloader, save_dir, args, _callbacks)
        
        # Get modality parameter from standard cfg system (ä¸è®­ç»ƒå™¨ä¿æŒä¸€è‡´)
        # Modality validation is handled by cfg system, no local validation needed
        # Handle both dict and object-like args
        if args:
            if isinstance(args, dict):
                self.modality = args.get('modality', None)
            else:
                self.modality = getattr(args, 'modality', None)
        else:
            self.modality = None
        
        # Initialize modality-specific attributes
        self.is_dual_modal = self.modality is None
        self.is_single_modal = self.modality is not None
        
        # æ—¥å¿—è¾“å‡º
        if self.modality:
            LOGGER.info(f"åˆå§‹åŒ–MultiModalDetectionValidator - å•æ¨¡æ€éªŒè¯æ¨¡å¼: {self.modality}-only")
        else:
            LOGGER.info("åˆå§‹åŒ–MultiModalDetectionValidator - åŒæ¨¡æ€éªŒè¯æ¨¡å¼")
        
        # åˆå§‹åŒ–å¤šæ¨¡æ€é…ç½®ï¼ˆç¨ååœ¨æœ‰dataå±æ€§æ—¶è§£æï¼‰
        self.multimodal_config = None

    @smart_inference_mode()
    def __call__(self, trainer=None, model=None):
        """
        æ‰§è¡ŒéªŒè¯è¿‡ç¨‹ï¼Œæ”¯æŒ6é€šé“å¤šæ¨¡æ€è¾“å…¥ã€‚
        
        é‡å†™åŸºç±»æ–¹æ³•ä»¥æ”¯æŒ6é€šé“warmupå’Œå¤šæ¨¡æ€æ•°æ®å¤„ç†ã€‚
        """
        self.training = trainer is not None
        augment = self.args.augment and (not self.training)
        if self.training:
            self.device = trainer.device
            # å…³é”®ä¿®å¤ï¼šä¿æŠ¤å¤šæ¨¡æ€éªŒè¯å™¨çš„dataé…ç½®ä¸è¢«è¦†ç›–
            # åªæœ‰å½“éªŒè¯å™¨æ²¡æœ‰dataé…ç½®æ—¶æ‰ä»trainerè·å–
            if self.data is None:
                self.data = trainer.data
            # force FP16 val during training
            self.args.half = self.device.type != "cpu" and trainer.amp
            model = trainer.ema.ema or trainer.model
            model = model.half() if self.args.half else model.float()
            self.loss = torch.zeros_like(trainer.loss_items, device=trainer.device)
            self.args.plots &= trainer.stopper.possible_stop or (trainer.epoch == trainer.epochs - 1)
            model.eval()
        else:
            callbacks.add_integration_callbacks(self)
            model = AutoBackend(
                weights=model or self.args.model,
                device=select_device(self.args.device, self.args.batch),
                dnn=self.args.dnn,
                data=self.args.data,
                fp16=self.args.half,
            )
            self.device = model.device  # update device
            self.args.half = model.fp16  # update half
            stride, pt, jit, engine = model.stride, model.pt, model.jit, model.engine
            imgsz = check_imgsz(self.args.imgsz, stride=stride)
            if engine:
                self.args.batch = model.batch_size
            elif not pt and not jit:
                self.args.batch = model.metadata.get("batch", 1)  # export.py models default to batch-size 1
                LOGGER.info(f"Setting batch={self.args.batch} input of shape ({self.args.batch}, 6, {imgsz}, {imgsz})")

            if str(self.args.data).split(".")[-1] in {"yaml", "yml"}:
                self.data = check_det_dataset(self.args.data)
            else:
                raise FileNotFoundError(emojis(f"Dataset '{self.args.data}' for task={self.args.task} not found âŒ"))

            if self.device.type in {"cpu", "mps"}:
                self.args.workers = 0  # faster CPU val as time dominated by inference, not dataloading
            if not pt:
                self.args.rect = False
            self.stride = model.stride  # used in get_dataloader() for padding
            self.dataloader = self.dataloader or self.get_dataloader(self.data.get(self.args.split), self.args.batch)

            model.eval()
            # å…³é”®ä¿®æ”¹ï¼š6é€šé“warmup instead of 3
            LOGGER.info("æ‰§è¡Œ6é€šé“å¤šæ¨¡æ€æ¨¡å‹warmup")
            model.warmup(imgsz=(1 if pt else self.args.batch, 6, imgsz, imgsz))  # warmup with 6 channels

        self.run_callbacks("on_val_start")
        dt = (
            Profile(device=self.device),
            Profile(device=self.device),
            Profile(device=self.device),
            Profile(device=self.device),
        )
        bar = TQDM(self.dataloader, desc=self.get_desc(), total=len(self.dataloader))
        self.init_metrics(de_parallel(model))
        self.jdict = []  # empty before each val
        for batch_i, batch in enumerate(bar):
            self.run_callbacks("on_val_batch_start")
            self.batch_i = batch_i
            # Preprocess
            with dt[0]:
                batch = self.preprocess(batch)

            # Inference
            with dt[1]:
                preds = model(batch["img"], augment=augment)

            # Loss
            with dt[2]:
                if self.training:
                    self.loss += model.loss(batch, preds)[1]

            # Postprocess
            with dt[3]:
                preds = self.postprocess(preds)

            self.update_metrics(preds, batch)
            if self.args.plots and batch_i < 3:
                self.plot_val_samples(batch, batch_i)
                self.plot_predictions(batch, preds, batch_i)

            self.run_callbacks("on_val_batch_end")
        stats = self.get_stats()
        self.check_stats(stats)
        self.speed = dict(zip(self.speed.keys(), (x.t / len(self.dataloader.dataset) * 1e3 for x in dt)))
        self.finalize_metrics()
        self.print_results()
        self.run_callbacks("on_val_end")
        if self.training:
            model.float()
            results = {**stats, **trainer.label_loss_items(self.loss.cpu() / len(self.dataloader), prefix="val")}
            return {k: round(float(v), 5) for k, v in results.items()}  # return results as 5 decimal place floats
        else:
            LOGGER.info(
                "Speed: {:.1f}ms preprocess, {:.1f}ms inference, {:.1f}ms loss, {:.1f}ms postprocess per image".format(
                    *tuple(self.speed.values())
                )
            )
            if self.args.save_json and self.jdict:
                with open(str(self.save_dir / "predictions.json"), "w") as f:
                    LOGGER.info(f"Saving {f.name}...")
                    json.dump(self.jdict, f)  # flatten and save
                stats = self.eval_json(stats)  # update stats
            if self.args.plots or self.args.save_json:
                LOGGER.info(f"Results saved to {colorstr('bold', self.save_dir)}")
            return stats

    def _parse_multimodal_config(self):
        """
        è§£æå’ŒéªŒè¯æ•°æ®é…ç½®æ–‡ä»¶ä¸­çš„å¤šæ¨¡æ€è®¾ç½®ã€‚
        
        ä¸MultiModalDetectionTrainerä½¿ç”¨ç›¸åŒçš„é…ç½®è§£æé€»è¾‘ï¼Œ
        ç¡®ä¿è®­ç»ƒå’ŒéªŒè¯é˜¶æ®µä½¿ç”¨ä¸€è‡´çš„å¤šæ¨¡æ€é…ç½®ã€‚
        
        ä¼˜å…ˆæ”¯æŒç”¨æˆ·æŒ‡å®šçš„å•æ¨¡æ€éªŒè¯å‚æ•°ã€‚
        
        Returns:
            dict: è§£æåçš„å¤šæ¨¡æ€é…ç½®
        """
        # ä¼˜å…ˆæ£€æŸ¥ç”¨æˆ·æŒ‡å®šçš„modalityå‚æ•°ï¼ˆå•æ¨¡æ€éªŒè¯ï¼‰
        if self.modality:
            # æ„å»ºå•æ¨¡æ€é…ç½® - æ™ºèƒ½ç¡®å®šXæ¨¡æ€ç±»å‹
            if self.modality == 'rgb':
                # RGBå•æ¨¡æ€ï¼šä½¿ç”¨RGB + åŠ¨æ€ç¡®å®šçš„Xæ¨¡æ€è¿›è¡Œé›¶å¡«å……
                x_modality = self._determine_x_modality_from_data()
                config = {
                    'models': ['rgb', x_modality],
                    'modalities': {
                        'rgb': 'images',
                        x_modality: f'images_{x_modality}'
                    }
                }
                LOGGER.info(f"RGBå•æ¨¡æ€éªŒè¯ï¼ŒåŠ¨æ€ç¡®å®šXæ¨¡æ€: {x_modality}")
            else:
                # å¤„ç† 'X' ç‰¹æ®Šæ ‡è®°ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
                if self.modality.upper() == 'X':
                    # 'X' æ˜¯ç‰¹æ®Šæ ‡è®°ï¼Œéœ€è¦è§£æä¸ºå®é™…çš„Xæ¨¡æ€
                    actual_x_modality = self._determine_x_modality_from_data()
                    x_modality_path = self._get_x_modality_path(actual_x_modality)
                    
                    config = {
                        'models': ['rgb', actual_x_modality],
                        'modalities': {
                            'rgb': 'images',
                            actual_x_modality: x_modality_path
                        }
                    }
                    LOGGER.info(f"Xæ¨¡æ€å•æ¨¡æ€éªŒè¯: {actual_x_modality}-only (ä»'X'è§£æ)")
                else:
                    # ç”¨æˆ·æŒ‡å®šäº†å…·ä½“çš„æ¨¡æ€åç§°ï¼ˆå¦‚ 'depth', 'thermal', 'ir' ç­‰ï¼‰
                    x_modality_path = self._get_x_modality_path(self.modality)
                    
                    config = {
                        'models': ['rgb', self.modality],
                        'modalities': {
                            'rgb': 'images',
                            self.modality: x_modality_path
                        }
                    }
                    LOGGER.info(f"Xæ¨¡æ€å•æ¨¡æ€éªŒè¯: {self.modality}-only")
            
            return config
        
        # åŒæ¨¡æ€éªŒè¯ï¼šä½¿ç”¨åŸæœ‰é…ç½®è§£æé€»è¾‘ï¼ˆä¼˜å…ˆä»æ•°æ®é…ç½®è¯»å–ï¼‰
        config = self._get_default_multimodal_config()
        
        if not self.data:
            LOGGER.warning("éªŒè¯å™¨æœªæä¾›æ•°æ®é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å¤šæ¨¡æ€é…ç½®: rgb+depth")
            return config
        
        # è§£æmodality_usedå­—æ®µï¼ˆä½¿ç”¨çš„æ¨¡æ€ç»„åˆï¼‰
        if 'modality_used' in self.data:
            modality_used = self.data['modality_used']

            # éªŒè¯modality_usedæ ¼å¼
            if not isinstance(modality_used, list):
                raise ValueError(f"éªŒè¯é…ç½®ä¸­'modality_used'å¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œå½“å‰ä¸º: {type(modality_used)}")

            if len(modality_used) != 2:
                raise ValueError(f"å¤šæ¨¡æ€éªŒè¯è¦æ±‚æ°å¥½2ä¸ªæ¨¡æ€ï¼Œå½“å‰æä¾›: {len(modality_used)} - {modality_used}")

            if 'rgb' not in modality_used:
                raise ValueError(f"å¤šæ¨¡æ€éªŒè¯å¿…é¡»åŒ…å«'rgb'æ¨¡æ€ï¼Œå½“å‰: {modality_used}")

            config['models'] = modality_used
            LOGGER.info(f"éªŒè¯ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡æ€ç»„åˆ: {modality_used}")
        else:
            LOGGER.info(f"éªŒè¯æœªæ‰¾åˆ°'modality_used'é…ç½®ï¼Œä½¿ç”¨é»˜è®¤ç»„åˆ: {config['models']}")
        
        # è§£æmodalityå­—æ®µï¼ˆæ¨¡æ€è·¯å¾„æ˜ å°„ï¼‰
        if 'modality' in self.data:
            modality_paths = self.data['modality']

            # éªŒè¯modalityæ ¼å¼
            if not isinstance(modality_paths, dict):
                raise ValueError(f"éªŒè¯é…ç½®ä¸­'modality'å¿…é¡»æ˜¯å­—å…¸æ ¼å¼ï¼Œå½“å‰ä¸º: {type(modality_paths)}")

            # åˆå§‹åŒ–modalitiesé…ç½®
            modalities = {'rgb': 'images'}  # RGBé»˜è®¤è·¯å¾„

            # éªŒè¯æ‰€æœ‰å¿…éœ€æ¨¡æ€éƒ½æœ‰è·¯å¾„é…ç½®
            for modality in config['models']:
                if modality == 'rgb':
                    continue  # RGBå·²è®¾ç½®é»˜è®¤è·¯å¾„
                elif modality in modality_paths:
                    modalities[modality] = modality_paths[modality]
                else:
                    modalities[modality] = f'images_{modality}'  # Xæ¨¡æ€é»˜è®¤è·¯å¾„
                    LOGGER.warning(f"éªŒè¯æœªæ‰¾åˆ°'{modality}'æ¨¡æ€è·¯å¾„é…ç½®ï¼Œä½¿ç”¨é»˜è®¤: images_{modality}")

            config['modalities'] = modalities
            LOGGER.info(f"éªŒè¯ä½¿ç”¨é…ç½®ä¸­çš„æ¨¡æ€è·¯å¾„æ˜ å°„: {modalities}")
        else:
            # ä¸ºå½“å‰æ¨¡æ€ç»„åˆç”Ÿæˆé»˜è®¤è·¯å¾„æ˜ å°„
            x_modality = [m for m in config['models'] if m != 'rgb'][0]
            config['modalities']['rgb'] = 'images'
            config['modalities'][x_modality] = f'images_{x_modality}'
            LOGGER.info(f"éªŒè¯æœªæ‰¾åˆ°'modality'é…ç½®ï¼Œç”Ÿæˆé»˜è®¤è·¯å¾„æ˜ å°„: {config['modalities']}")
        
        return config
    
    def _get_x_modality_path(self, modality_name):
        """
        è·å–æŒ‡å®šæ¨¡æ€çš„å®é™…è·¯å¾„ã€‚
        
        ä¼˜å…ˆä»data.yamlçš„modalityå­—æ®µè¯»å–ï¼Œ
        å¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤æ ¼å¼ 'images_{modality_name}'ã€‚
        
        Args:
            modality_name (str): æ¨¡æ€åç§°ï¼ˆå¦‚ 'ir', 'depth', 'thermal'ï¼‰
            
        Returns:
            str: æ¨¡æ€å¯¹åº”çš„ç›®å½•è·¯å¾„
        """
        # ä¼˜å…ˆä»data.yamlçš„modalityå­—æ®µè¯»å–
        if self.data and 'modality' in self.data:
            modality_paths = self.data['modality']
            if isinstance(modality_paths, dict) and modality_name in modality_paths:
                return modality_paths[modality_name]
        
        # å‘åå…¼å®¹ï¼šæ£€æŸ¥modalitieså­—æ®µ
        if self.data and 'modalities' in self.data:
            modalities = self.data['modalities']
            if isinstance(modalities, dict) and modality_name in modalities:
                return modalities[modality_name]
        
        # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
        return f'images_{modality_name}'
    
    def _determine_x_modality_from_data(self):
        """
        æ™ºèƒ½ç¡®å®šXæ¨¡æ€ç±»å‹ï¼Œé¿å…ç¡¬ç¼–ç depthã€‚ï¼ˆä¸è®­ç»ƒå™¨å®Œå…¨ä¸€è‡´ï¼‰

        ä¼˜å…ˆçº§:
        1. ä»data.yamlçš„modality_usedå­—æ®µè¯»å–ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        2. ä»data.yamlçš„modelså­—æ®µè¯»å–
        3. ä»modalityå­—æ®µæ¨æ–­
        4. ä»æ•°æ®ç›®å½•ç»“æ„æ¨æ–­
        5. æœ€åä½¿ç”¨depthä½œä¸ºfallback

        Returns:
            str: Xæ¨¡æ€ç±»å‹æ ‡è¯†ç¬¦
        """
        # æ–¹æ³•1: ä»data.yamlçš„modality_usedå­—æ®µè¯»å–ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if self.data and 'modality_used' in self.data:
            modality_used = self.data['modality_used']
            if isinstance(modality_used, list) and len(modality_used) >= 2:
                x_modalities = [m for m in modality_used if m != 'rgb']
                if x_modalities:
                    x_modality = x_modalities[0]
                    LOGGER.info(f"éªŒè¯-ä»data.yamlçš„modality_usedè¯»å–Xæ¨¡æ€: {x_modality}")
                    return x_modality

        # æ–¹æ³•2: ä»data.yamlçš„modelså­—æ®µè¯»å–ï¼ˆå‘åå…¼å®¹ï¼‰
        if self.data and 'models' in self.data:
            models = self.data['models']
            if isinstance(models, list) and len(models) >= 2:
                x_modalities = [m for m in models if m != 'rgb']
                if x_modalities:
                    x_modality = x_modalities[0]
                    LOGGER.info(f"éªŒè¯-ä»æ•°æ®é…ç½®è¯»å–Xæ¨¡æ€: {x_modality}")
                    return x_modality
        
        # æ–¹æ³•3: ä»modalityå­—æ®µæ¨æ–­ï¼ˆæ£€æŸ¥é…ç½®çš„æ¨¡æ€ç±»å‹ï¼‰
        if self.data and 'modality' in self.data:
            modality = self.data['modality']
            if isinstance(modality, dict):
                x_modalities = [k for k in modality.keys() if k != 'rgb']
                if x_modalities:
                    x_modality = x_modalities[0]
                    LOGGER.info(f"éªŒè¯-ä»data.yamlçš„modalityé…ç½®æ¨æ–­Xæ¨¡æ€: {x_modality}")
                    return x_modality

        # æ–¹æ³•4: æ£€æŸ¥modalitiesé…ç½®ï¼ˆå‘åå…¼å®¹ï¼‰
        if self.data and 'modalities' in self.data:
            modalities = self.data['modalities']
            if isinstance(modalities, dict):
                x_modalities = [k for k in modalities.keys() if k != 'rgb']
                if x_modalities:
                    x_modality = x_modalities[0]
                    LOGGER.info(f"éªŒè¯-ä»modalitiesé…ç½®æ¨æ–­Xæ¨¡æ€: {x_modality}")
                    return x_modality

        # æ–¹æ³•5: ä»æ•°æ®ç›®å½•ç»“æ„æ¨æ–­ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰
        if self.data and 'path' in self.data:
            try:
                import os
                data_path = self.data['path']
                if os.path.exists(data_path):
                    # æŸ¥æ‰¾images_xxxç›®å½•
                    for item in os.listdir(data_path):
                        if item.startswith('images_') and item != 'images':
                            x_modality = item.replace('images_', '')
                            LOGGER.info(f"éªŒè¯-ä»ç›®å½•ç»“æ„æ¨æ–­Xæ¨¡æ€: {x_modality}")
                            return x_modality
            except Exception as e:
                LOGGER.debug(f"éªŒè¯-ç›®å½•ç»“æ„æ¨æ–­å¤±è´¥: {e}")
        
        # Fallback: ä½¿ç”¨depthä½œä¸ºé»˜è®¤å€¼
        LOGGER.warning("éªŒè¯-æ— æ³•è‡ªåŠ¨ç¡®å®šXæ¨¡æ€ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤å€¼: depth")
        return 'depth'
    
    def _get_default_multimodal_config(self):
        """
        è·å–é»˜è®¤çš„å¤šæ¨¡æ€éªŒè¯é…ç½®ï¼Œä¼˜å…ˆä»æ•°æ®é…ç½®æ–‡ä»¶è¯»å–ã€‚ï¼ˆä¸è®­ç»ƒå™¨ä¿æŒä¸€è‡´ï¼‰
        
        Returns:
            dict: é»˜è®¤å¤šæ¨¡æ€é…ç½®
        """
        # ä¼˜å…ˆä»æ•°æ®é…ç½®è¯»å–ï¼ˆä¼˜å…ˆæ£€æŸ¥modality_usedå­—æ®µï¼‰
        if self.data and 'modality_used' in self.data:
            modality_used = self.data['modality_used']
            if isinstance(modality_used, list) and len(modality_used) >= 2:
                LOGGER.info(f"éªŒè¯-ä»modality_usedé…ç½®è¯»å–æ¨¡æ€ç»„åˆ: {modality_used}")
                config = {
                    'models': modality_used,
                    'modalities': {
                        'rgb': 'images'  # RGBè·¯å¾„å›ºå®š
                    }
                }
                # ä¸ºéRGBæ¨¡æ€ç”Ÿæˆè·¯å¾„ï¼ˆä»modalityå­—æ®µè¯»å–æˆ–ä½¿ç”¨é»˜è®¤ï¼‰
                for modality in modality_used:
                    if modality != 'rgb':
                        if self.data and 'modality' in self.data and modality in self.data['modality']:
                            config['modalities'][modality] = self.data['modality'][modality]
                        else:
                            config['modalities'][modality] = f'images_{modality}'
                return config

        # å¤‡é€‰ï¼šä»modelså­—æ®µè¯»å–
        if self.data and 'models' in self.data:
            models = self.data['models']
            if isinstance(models, list) and len(models) >= 2:
                LOGGER.info(f"éªŒè¯-ä»modelsé…ç½®è¯»å–æ¨¡æ€ç»„åˆ: {models}")
                config = {
                    'models': models,
                    'modalities': {
                        'rgb': 'images'  # RGBè·¯å¾„å›ºå®š
                    }
                }
                # ä¸ºéRGBæ¨¡æ€ç”Ÿæˆé»˜è®¤è·¯å¾„
                for modality in models:
                    if modality != 'rgb':
                        config['modalities'][modality] = f'images_{modality}'
                return config
        
        # æ™ºèƒ½æ¨æ–­é»˜è®¤é…ç½®
        x_modality = self._determine_x_modality_from_data()
        config = {
            'models': ['rgb', x_modality],  # åŠ¨æ€ç¡®å®šçš„æ¨¡æ€ç»„åˆ
            'modalities': {  # åŠ¨æ€ç”Ÿæˆçš„æ¨¡æ€è·¯å¾„æ˜ å°„
                'rgb': 'images',
                x_modality: f'images_{x_modality}'
            }
        }
        LOGGER.info(f"éªŒè¯-ç”Ÿæˆé»˜è®¤å¤šæ¨¡æ€é…ç½®: rgb+{x_modality}")
        return config

    def build_dataset(self, img_path, mode="val", batch=None):
        """
        æ„å»ºå¤šæ¨¡æ€éªŒè¯æ•°æ®é›†ã€‚
        
        é‡å†™çˆ¶ç±»æ–¹æ³•ï¼Œé€šè¿‡ä¼ é€’multi_modal_image=Trueå‚æ•°å¯ç”¨YOLOMultiModalImageDatasetï¼Œ
        ç¡®ä¿éªŒè¯é˜¶æ®µä¹Ÿèƒ½æ­£ç¡®å¤„ç†å¤šæ¨¡æ€æ•°æ®ï¼Œä¸è®­ç»ƒå™¨ä¿æŒä¸€è‡´ã€‚
        
        Args:
            img_path (str): å›¾åƒè·¯å¾„
            mode (str): æ¨¡å¼ï¼ˆval/testï¼‰
            batch (int, optional): æ‰¹æ¬¡å¤§å°
            
        Returns:
            YOLOMultiModalImageDataset: å¤šæ¨¡æ€éªŒè¯æ•°æ®é›†å¯¹è±¡
        """
        # å»¶è¿Ÿè§£æå¤šæ¨¡æ€é…ç½®ï¼ˆç¡®ä¿dataå±æ€§å·²è®¾ç½®ï¼‰
        if self.multimodal_config is None:
            self.multimodal_config = self._parse_multimodal_config()
            LOGGER.info(f"å¤šæ¨¡æ€éªŒè¯é…ç½®è§£æå®Œæˆ - æ¨¡æ€: {self.multimodal_config['models']}")
        
        # ä½¿ç”¨è§£æåçš„æ¨¡æ€é…ç½®
        modalities = self.multimodal_config['models']
        modalities_dict = self.multimodal_config['modalities']

        # è·å–Xæ¨¡æ€ä¿¡æ¯
        x_modalities = [m for m in modalities if m != 'rgb']
        x_modality = x_modalities[0] if x_modalities else None
        x_modality_dir = modalities_dict.get(x_modality) if x_modality else None

        # è·å–strideå‚æ•°ï¼ˆç¡®ä¿å·²è®¾ç½®ï¼‰
        stride = self.stride if hasattr(self, 'stride') and self.stride else 32

        # ä¼˜åŒ–æ—¥å¿—è¾“å‡ºï¼ŒåŒºåˆ†å•æ¨¡æ€å’ŒåŒæ¨¡æ€éªŒè¯ï¼Œä¸è®­ç»ƒå™¨ä¿æŒä¸€è‡´çš„æ ¼å¼
        if self.modality:
            # å•æ¨¡æ€éªŒè¯æ—¥å¿— - ä¸è®­ç»ƒå™¨æ ¼å¼ä¿æŒä¸€è‡´
            LOGGER.info(f"æ„å»ºå¤šæ¨¡æ€éªŒè¯æ•°æ®é›† - æ¨¡å¼: {mode}, è·¯å¾„: {img_path}, æ¨¡æ€: {modalities}")
            LOGGER.info(f"å¯ç”¨å•æ¨¡æ€éªŒè¯: {self.modality}-onlyï¼Œå°†åº”ç”¨æ™ºèƒ½æ¨¡æ€å¡«å……")
        else:
            # åŒæ¨¡æ€éªŒè¯æ—¥å¿— - ä¸è®­ç»ƒå™¨æ ¼å¼ä¿æŒä¸€è‡´
            LOGGER.info(f"æ„å»ºå¤šæ¨¡æ€éªŒè¯æ•°æ®é›† - æ¨¡å¼: {mode}, è·¯å¾„: {img_path}, æ¨¡æ€: {modalities}")

        # è°ƒç”¨build_yolo_datasetï¼Œä¼ é€’multi_modal_image=Trueå¯ç”¨å¤šæ¨¡æ€æ•°æ®é›†
        return build_yolo_dataset(
            self.args, img_path, batch, self.data,
            mode=mode,
            rect=True,  # éªŒè¯æ¨¡å¼é»˜è®¤ä½¿ç”¨çŸ©å½¢æ¨ç†
            stride=stride,
            multi_modal_image=True,  # å…³é”®å‚æ•°ï¼šå¯ç”¨YOLOMultiModalImageDataset
            x_modality=x_modality,  # ä¼ é€’Xæ¨¡æ€ç±»å‹
            x_modality_dir=x_modality_dir,  # ä¼ é€’Xæ¨¡æ€ç›®å½•è·¯å¾„
            modalities=modalities,  # ä¼ é€’æ¨¡æ€é…ç½®ï¼ˆå‘åå…¼å®¹ï¼‰
            # ç§»é™¤train_modalityå‚æ•°ä¼ é€’ï¼Œæ”¹ä¸ºåœ¨éªŒè¯å™¨ä¸­å®ç°æ¨¡æ€æ¶ˆèé€»è¾‘
        )

    def init_metrics(self, model):
        """
        åˆå§‹åŒ–è¯„ä¼°æŒ‡æ ‡ã€‚
        
        å¤šæ¨¡æ€éªŒè¯ä½¿ç”¨æ ‡å‡†YOLOè¯„ä¼°æŒ‡æ ‡ï¼š
        - mAP@0.5
        - mAP@0.5:0.95
        - Precision
        - Recall
        
        ä¿æŒä¸DetectionValidatorå®Œå…¨ä¸€è‡´çš„è¯„ä¼°ä½“ç³»ã€‚
        """
        super().init_metrics(model)
        
        # ç¡®ä¿strideå±æ€§è¢«æ­£ç¡®è®¾ç½®
        if model and not hasattr(self, 'stride'):
            self.stride = max(int(de_parallel(model).stride.max() if hasattr(model, 'stride') else 0), 32)
        
        # LOGGER.info("åˆå§‹åŒ–å¤šæ¨¡æ€è¯„ä¼°æŒ‡æ ‡ - ä½¿ç”¨æ ‡å‡†YOLOæŒ‡æ ‡")
        
    def preprocess(self, batch):
        """
        é¢„å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼ŒåŒ…æ‹¬æ¨¡æ€æ¶ˆèé€»è¾‘ã€‚
        
        ç¡®ä¿6é€šé“æ•°æ®æ­£ç¡®å¤„ç†ï¼Œä¿æŒä¸è®­ç»ƒé˜¶æ®µä¸€è‡´çš„é¢„å¤„ç†æµç¨‹ã€‚
        å½“å¯ç”¨å•æ¨¡æ€éªŒè¯æ—¶ï¼Œåº”ç”¨æ¨¡æ€æ¶ˆèé€»è¾‘ã€‚
        
        Args:
            batch (dict): åŒ…å«å›¾åƒå’Œæ ‡ç­¾çš„æ‰¹æ¬¡æ•°æ®
            
        Returns:
            dict: é¢„å¤„ç†åçš„æ‰¹æ¬¡æ•°æ®
        """
        # è°ƒç”¨çˆ¶ç±»é¢„å¤„ç†æ–¹æ³•
        batch = super().preprocess(batch)
        
        # éªŒè¯6é€šé“è¾“å…¥
        if batch["img"].shape[1] != 6:
            LOGGER.warning(f"æœŸæœ›6é€šé“è¾“å…¥ï¼Œä½†æ”¶åˆ° {batch['img'].shape[1]} é€šé“")
            return batch
        
        # åº”ç”¨æ¨¡æ€æ¶ˆèé€»è¾‘
        if self.modality:
            self._apply_modality_ablation(batch)
            LOGGER.debug(f"å·²åº”ç”¨{self.modality}æ¨¡æ€æ¶ˆè")
        
        return batch
        
    def _apply_modality_ablation(self, batch):
        """
        åº”ç”¨æ¨¡æ€æ¶ˆèé€»è¾‘ï¼Œé€šè¿‡å°†éé€‰å®šæ¨¡æ€çš„é€šé“ç½®é›¶æ¥å®ç°å•æ¨¡æ€éªŒè¯ã€‚
        
        é€šé“æ˜ å°„ï¼š
        - å‰3é€šé“ (0-2)ï¼šXæ¨¡æ€æ•°æ®ï¼ˆdepth/thermalç­‰ï¼‰
        - å3é€šé“ (3-5)ï¼šRGBæ•°æ®
        
        Args:
            batch (dict): åŒ…å«å›¾åƒæ•°æ®çš„æ‰¹æ¬¡
        """
        if not self.modality:
            return
        
        images = batch["img"]  # Shape: [B, 6, H, W]
        
        if self.modality == 'rgb':
            # RGBå•æ¨¡æ€éªŒè¯ï¼šå°†Xæ¨¡æ€é€šé“(å‰3é€šé“)ç½®é›¶
            images[:, :3, :, :] = 0
            LOGGER.debug("å•æ¨¡æ€RGBéªŒè¯: Xæ¨¡æ€é€šé“å·²ç½®é›¶")
        elif self.modality.upper() == 'X':
            # Xæ¨¡æ€éªŒè¯ï¼šå°†RGBé€šé“(å3é€šé“)ç½®é›¶
            images[:, 3:, :, :] = 0
            LOGGER.debug("å•æ¨¡æ€XéªŒè¯: RGBé€šé“å·²ç½®é›¶")
        else:
            # å…·ä½“Xæ¨¡æ€éªŒè¯ï¼ˆå¦‚depthã€thermalç­‰ï¼‰ï¼šå°†RGBé€šé“ç½®é›¶
            images[:, 3:, :, :] = 0
            LOGGER.debug(f"å•æ¨¡æ€{self.modality}éªŒè¯: RGBé€šé“å·²ç½®é›¶")
        
        batch["img"] = images
        
    def plot_val_samples(self, batch, ni):
        """
        ç»˜åˆ¶éªŒè¯æ ·æœ¬ã€‚
        
        å¯¹äºå¤šæ¨¡æ€æ•°æ®ï¼Œåˆ†ç¦»RGBå’ŒXæ¨¡æ€è¿›è¡Œå¯è§†åŒ–ï¼Œæä¾›æ›´å…¨é¢çš„éªŒè¯æ ·æœ¬å±•ç¤ºã€‚
        
        Args:
            batch (dict): æ‰¹æ¬¡æ•°æ®
            ni (int): æ‰¹æ¬¡ç´¢å¼•
        """
        from ultralytics.utils.plotting import plot_images
        
        # è·å–6é€šé“å›¾åƒæ•°æ®
        multimodal_images = batch["img"]  # Shape: (batch, 6, H, W)
        
        # åˆ†ç¦»RGBå’ŒXæ¨¡æ€ï¼ˆæ³¨æ„ï¼šæ ¹æ®ä¹‹å‰çš„ä¿®å¤ï¼Œå®é™…é¡ºåºå¯èƒ½æ˜¯åçš„ï¼‰
        rgb_images = multimodal_images[:, 3:, :, :]      # å3é€šé“ï¼šå®é™…çš„RGB
        x_modal_images = multimodal_images[:, :3, :, :]  # å‰3é€šé“ï¼šå®é™…çš„Xæ¨¡æ€
        
        # è·å–Xæ¨¡æ€ç±»å‹ - ä½¿ç”¨æ–°çš„å®‰å…¨æ–¹æ³•
        x_modality = self._get_x_modality_type()
        
        # 1. ç»˜åˆ¶RGBæ¨¡æ€éªŒè¯æ ·æœ¬ï¼ˆä¸»è¦ç”¨äºæ ‡æ³¨å±•ç¤ºï¼‰
        plot_images(
            rgb_images,
            batch["batch_idx"],
            batch["cls"].squeeze(-1),
            batch["bboxes"],
            paths=batch["im_file"],
            fname=self.save_dir / f"val_batch{ni}_labels.jpg",
            names=self.names,
            on_plot=self.on_plot,
        )
        
        # 2. ç»˜åˆ¶Xæ¨¡æ€éªŒè¯æ ·æœ¬ï¼ˆç”¨äºæŸ¥çœ‹çº¢å¤–å›¾åƒè´¨é‡ï¼‰
        try:
            # å¤„ç†Xæ¨¡æ€æ•°æ®ä»¥ä¾¿å¯è§†åŒ–
            x_visual = self._process_x_modality_for_visualization(x_modal_images, x_modality)
            
            plot_images(
                x_visual,
                batch["batch_idx"],
                batch["cls"].squeeze(-1),
                batch["bboxes"],
                paths=[p.replace('.jpg', f'_{x_modality}.jpg') for p in batch["im_file"]],
                fname=self.save_dir / f"val_batch{ni}_labels_{x_modality}.jpg",
                names=self.names,
                on_plot=self.on_plot,
            )
            
            # 3. åˆ›å»ºå¹¶æ’å¤šæ¨¡æ€å¯¹æ¯”å›¾
            side_by_side_images = self._create_side_by_side_visualization(rgb_images, x_visual)
            plot_images(
                side_by_side_images,
                batch["batch_idx"],
                batch["cls"].squeeze(-1),
                self._adjust_bboxes_for_side_by_side(batch["bboxes"]),
                paths=[p.replace('.jpg', '_multimodal.jpg') for p in batch["im_file"]],
                fname=self.save_dir / f"val_batch{ni}_labels_multimodal.jpg",
                names=self.names,
                on_plot=self.on_plot,
            )
            
        except Exception as e:
            LOGGER.warning(f"ç»˜åˆ¶{x_modality}æ¨¡æ€éªŒè¯æ ·æœ¬å¤±è´¥: {e}")
        
    def plot_predictions(self, batch, preds, ni):
        """
        ç»˜åˆ¶é¢„æµ‹ç»“æœã€‚
        
        åœ¨RGBã€çº¢å¤–æ¨¡æ€ä»¥åŠå¤šæ¨¡æ€å¯¹æ¯”å›¾ä¸Šç»˜åˆ¶é¢„æµ‹è¾¹ç•Œæ¡†ã€‚
        
        Args:
            batch (dict): æ‰¹æ¬¡æ•°æ®
            preds (list): é¢„æµ‹ç»“æœ
            ni (int): æ‰¹æ¬¡ç´¢å¼•
        """
        from ultralytics.utils.plotting import plot_images, output_to_target
        
        # è·å–RGBå›¾åƒï¼ˆå3é€šé“ï¼‰
        multimodal_images = batch["img"]
        rgb_images = multimodal_images[:, 3:, :, :]
        x_modal_images = multimodal_images[:, :3, :, :]
        
        # è·å–Xæ¨¡æ€ç±»å‹ - ä½¿ç”¨æ–°çš„å®‰å…¨æ–¹æ³•
        x_modality = self._get_x_modality_type()
        
        # 1. åœ¨RGBå›¾åƒä¸Šç»˜åˆ¶é¢„æµ‹ï¼ˆä¸»è¦ç»“æœï¼‰
        plot_images(
            rgb_images,
            *output_to_target(preds, max_det=self.args.max_det),
            paths=batch["im_file"],
            fname=self.save_dir / f"val_batch{ni}_pred.jpg",
            names=self.names,
            on_plot=self.on_plot,
        )
        
        # 2. åœ¨Xæ¨¡æ€å›¾åƒä¸Šç»˜åˆ¶é¢„æµ‹ï¼ˆç”¨äºåˆ†ææ¨¡æ€æ•ˆæœï¼‰
        try:
            # å¤„ç†Xæ¨¡æ€æ•°æ®ä»¥ä¾¿å¯è§†åŒ–
            x_visual = self._process_x_modality_for_visualization(x_modal_images, x_modality)
            
            plot_images(
                x_visual,
                *output_to_target(preds, max_det=self.args.max_det),
                paths=[p.replace('.jpg', f'_{x_modality}.jpg') for p in batch["im_file"]],
                fname=self.save_dir / f"val_batch{ni}_pred_{x_modality}.jpg",
                names=self.names,
                on_plot=self.on_plot,
            )
            
            # 3. åˆ›å»ºå¤šæ¨¡æ€å¯¹æ¯”é¢„æµ‹å›¾
            side_by_side_images = self._create_side_by_side_visualization(rgb_images, x_visual)
            plot_images(
                side_by_side_images,
                *output_to_target(preds, max_det=self.args.max_det),
                paths=[p.replace('.jpg', '_multimodal.jpg') for p in batch["im_file"]],
                fname=self.save_dir / f"val_batch{ni}_pred_multimodal.jpg",
                names=self.names,
                on_plot=self.on_plot,
            )
            
        except Exception as e:
            LOGGER.warning(f"ç»˜åˆ¶{x_modality}æ¨¡æ€é¢„æµ‹ç»“æœå¤±è´¥: {e}")

    def _process_x_modality_for_visualization(self, x_modal_images, x_modality):
        """
        å¤„ç†Xæ¨¡æ€æ•°æ®ç”¨äºå¯è§†åŒ–ï¼ˆä»è®­ç»ƒå™¨å¤åˆ¶çš„æ–¹æ³•ï¼‰ã€‚
        
        Args:
            x_modal_images (torch.Tensor): Xæ¨¡æ€å›¾åƒæ•°æ® (batch, 3, H, W)
            x_modality (str): Xæ¨¡æ€ç±»å‹
            
        Returns:
            torch.Tensor: å¤„ç†åçš„3é€šé“å¯è§†åŒ–æ•°æ®
        """
        import torch
        import numpy as np
        import cv2
        
        # è®°ä½åŸå§‹è®¾å¤‡
        original_device = x_modal_images.device
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå•é€šé“é‡å¤ï¼ˆå¦‚æ·±åº¦å›¾çš„ [D,D,D] æ ¼å¼ï¼‰
        if torch.allclose(x_modal_images[:, 0:1, :, :], x_modal_images[:, 1:2, :, :]) and \
           torch.allclose(x_modal_images[:, 1:2, :, :], x_modal_images[:, 2:3, :, :]):
            
            # æå–å•é€šé“æ•°æ®
            single_channel = x_modal_images[:, 0:1, :, :]  # (batch, 1, H, W)
            
            # åº”ç”¨ä¼ªå½©è‰²æ˜ å°„
            colorized_images = []
            for i in range(single_channel.shape[0]):
                # è½¬æ¢ä¸ºnumpyå¹¶å½’ä¸€åŒ–åˆ°0-255
                img_np = single_channel[i, 0].cpu().numpy()
                if img_np.max() <= 1.0:
                    img_np = (img_np * 255).astype(np.uint8)
                else:
                    img_np = np.clip(img_np, 0, 255).astype(np.uint8)
                
                # åº”ç”¨é¢œè‰²æ˜ å°„ï¼ˆæ ¹æ®æ¨¡æ€ç±»å‹é€‰æ‹©ï¼‰
                if x_modality in ['depth']:
                    colormap = cv2.COLORMAP_VIRIDIS  # æ·±åº¦ç”¨ç»¿è“è‰²ç³»ï¼Œä¸çº¢å¤–å½¢æˆé²œæ˜å¯¹æ¯”
                elif x_modality in ['thermal', 'infrared', 'ir']:
                    colormap = cv2.COLORMAP_INFERNO  # çƒ­çº¢å¤–ç”¨çº¢é»„è‰²ç³»
                else:
                    colormap = cv2.COLORMAP_JET  # å…¶ä»–ç”¨å½©è™¹è‰²
                colored_img = cv2.applyColorMap(img_np, colormap)
                colored_img = cv2.cvtColor(colored_img, cv2.COLOR_BGR2RGB)
                
                # è½¬æ¢å›tensoræ ¼å¼ (3, H, W) å¹¶ç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
                colored_tensor = torch.from_numpy(colored_img.transpose(2, 0, 1)).float().to(original_device)
                if colored_tensor.max() > 1.0:
                    colored_tensor /= 255.0
                    
                colorized_images.append(colored_tensor)
            
            return torch.stack(colorized_images)
        
        else:
            # ç¡®ä¿è¿”å›çš„å¼ é‡åœ¨åŸå§‹è®¾å¤‡ä¸Š
            return x_modal_images.to(original_device)

    def _create_side_by_side_visualization(self, rgb_images, x_images):
        """
        åˆ›å»ºRGBå’ŒXæ¨¡æ€çš„å¹¶æ’å¯è§†åŒ–ï¼ˆä»è®­ç»ƒå™¨å¤åˆ¶çš„æ–¹æ³•ï¼‰ã€‚
        
        Args:
            rgb_images (torch.Tensor): RGBå›¾åƒ (batch, 3, H, W)
            x_images (torch.Tensor): Xæ¨¡æ€å›¾åƒ (batch, 3, H, W)
            
        Returns:
            torch.Tensor: å¹¶æ’æ‹¼æ¥çš„å›¾åƒ (batch, 3, H, W*2)
        """
        import torch
        
        # ç¡®ä¿ä¸¤ä¸ªå¼ é‡åœ¨åŒä¸€è®¾å¤‡ä¸Š
        if rgb_images.device != x_images.device:
            x_images = x_images.to(rgb_images.device)
        
        # æ°´å¹³æ‹¼æ¥ä¸¤ä¸ªæ¨¡æ€çš„å›¾åƒ
        side_by_side = torch.cat([rgb_images, x_images], dim=3)  # åœ¨å®½åº¦ç»´åº¦æ‹¼æ¥
        
        return side_by_side
    
    def _adjust_bboxes_for_side_by_side(self, bboxes):
        """
        è°ƒæ•´è¾¹ç•Œæ¡†åæ ‡ä»¥é€‚åº”å¹¶æ’å›¾åƒï¼ˆä»è®­ç»ƒå™¨å¤åˆ¶çš„æ–¹æ³•ï¼‰ã€‚
        
        Args:
            bboxes (torch.Tensor): åŸå§‹è¾¹ç•Œæ¡†åæ ‡
            
        Returns:
            torch.Tensor: è°ƒæ•´åçš„è¾¹ç•Œæ¡†åæ ‡
        """
        # ä¸ºå¹¶æ’å›¾åƒå¤åˆ¶è¾¹ç•Œæ¡†ï¼šå·¦ä¾§RGBä¿æŒåŸæ ·ï¼Œå³ä¾§Xæ¨¡æ€éœ€è¦å¹³ç§»
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ ¹æ®å›¾åƒå®½åº¦è°ƒæ•´
        adjusted_bboxes = bboxes.clone()
        
        # ç”±äºplot_imageså‡½æ•°çš„é™åˆ¶ï¼Œè¿™é‡Œæš‚æ—¶ä¿æŒåŸæ ·
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„å¤„ç†é€»è¾‘
        
        return adjusted_bboxes

    def _get_x_modality_type(self):
        """
        å®‰å…¨åœ°è·å–Xæ¨¡æ€ç±»å‹ï¼Œæ”¯æŒå¤šç§åœºæ™¯ï¼š
        1. æ­£å¸¸åŒæ¨¡æ€éªŒè¯ï¼ˆä»data.yamlé…ç½®è§£æï¼‰
        2. å•æ¨¡æ€éªŒè¯ï¼ˆä»modalityå‚æ•°æ¨å¯¼ï¼‰
        3. é…ç½®è§£æå¤±è´¥çš„å›é€€å¤„ç†
        
        Returns:
            str: Xæ¨¡æ€ç±»å‹æ ‡è¯†ç¬¦
        """
        # åœºæ™¯1ï¼šå•æ¨¡æ€éªŒè¯ - ç›´æ¥ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„modalityå‚æ•°
        if self.modality and self.modality != 'rgb':
            LOGGER.debug(f"å•æ¨¡æ€éªŒè¯æ¨¡å¼ï¼ŒXæ¨¡æ€ç±»å‹: {self.modality}")
            return self.modality
        
        # åœºæ™¯2ï¼šå°è¯•ä»multimodal_configä¸­è·å–
        if (hasattr(self, 'multimodal_config') and 
            self.multimodal_config and 
            isinstance(self.multimodal_config, dict) and 
            'models' in self.multimodal_config and 
            isinstance(self.multimodal_config['models'], list)):
            
            # ä»modelsåˆ—è¡¨ä¸­æå–érgbçš„æ¨¡æ€
            non_rgb_modalities = [m for m in self.multimodal_config['models'] if m != 'rgb']
            if non_rgb_modalities:
                x_modality = non_rgb_modalities[0]
                LOGGER.debug(f"ä»multimodal_configè·å–Xæ¨¡æ€ç±»å‹: {x_modality}")
                return x_modality
        
        # åœºæ™¯3ï¼šå°è¯•ä»dataé…ç½®ä¸­ç›´æ¥è·å–
        if (hasattr(self, 'data') and self.data and isinstance(self.data, dict)):
            # ä¼˜å…ˆæŸ¥æ‰¾'modality_used'å­—æ®µï¼ˆæ–°æ ¼å¼ï¼‰
            if 'modality_used' in self.data and isinstance(self.data['modality_used'], list):
                non_rgb_modalities = [m for m in self.data['modality_used'] if m != 'rgb']
                if non_rgb_modalities:
                    x_modality = non_rgb_modalities[0]
                    LOGGER.debug(f"ä»dataé…ç½®è·å–Xæ¨¡æ€ç±»å‹(modality_used): {x_modality}")
                    return x_modality
            # å…¼å®¹æ—§æ ¼å¼'models'å­—æ®µ
            elif 'models' in self.data and isinstance(self.data['models'], list):
                non_rgb_modalities = [m for m in self.data['models'] if m != 'rgb']
                if non_rgb_modalities:
                    x_modality = non_rgb_modalities[0]
                    LOGGER.debug(f"ä»dataé…ç½®è·å–Xæ¨¡æ€ç±»å‹(models): {x_modality}")
                    return x_modality
        
        # åœºæ™¯4ï¼šå›é€€åˆ°é»˜è®¤å€¼ï¼ˆä¼˜å…ˆè€ƒè™‘depthè€Œéirï¼‰
        default_modality = 'depth'
        LOGGER.warning(f"æ— æ³•ä»é…ç½®ä¸­è·å–Xæ¨¡æ€ç±»å‹ï¼Œä½¿ç”¨é»˜è®¤å€¼: {default_modality}")
        return default_modality 