# Ultralytics YOLO ğŸš€, AGPL-3.0 license

from ultralytics.models.yolo.multimodal.val import MultiModalDetectionValidator
from ultralytics.utils.coco_metrics import COCOMetrics
from ultralytics.utils import LOGGER, colorstr, ops
from ultralytics.utils.torch_utils import de_parallel
from ultralytics.utils.ops import Profile
from ultralytics.utils import TQDM, callbacks
import torch
import numpy as np
import json
import csv
import time
from pathlib import Path
from tqdm import tqdm


class MultiModalCOCOValidator(MultiModalDetectionValidator):
    """
    å¤šæ¨¡æ€COCOéªŒè¯å™¨ï¼Œä½¿ç”¨COCOè¯„ä¼°æŒ‡æ ‡è¿›è¡Œå¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹éªŒè¯ã€‚
    
    è¿™ä¸ªç±»ç»§æ‰¿è‡ªMultiModalDetectionValidatorï¼Œä¿æŒå¤šæ¨¡æ€æ•°æ®å¤„ç†èƒ½åŠ›çš„åŒæ—¶
    ä½¿ç”¨COCOæ ‡å‡†è¯„ä¼°æŒ‡æ ‡ï¼Œæä¾›æ›´è¯¦ç»†çš„æ€§èƒ½åˆ†æã€‚
    
    ä¸»è¦ç‰¹ç‚¹ï¼š
    - æ”¯æŒRGB+Xå¤šæ¨¡æ€è¾“å…¥çš„COCOè¯„ä¼°
    - æ”¯æŒå•æ¨¡æ€éªŒè¯ï¼ˆmodalityå‚æ•°ï¼‰
    - æä¾›12é¡¹æ ‡å‡†COCOæŒ‡æ ‡
    - ä¿æŒä¸è®­ç»ƒå™¨ä¸€è‡´çš„å¤šæ¨¡æ€é…ç½®è§£æ
    - å¤„ç†åŸå§‹å›¾åƒå°ºå¯¸ç”¨äºç²¾ç¡®é¢ç§¯è®¡ç®—
    
    COCOæŒ‡æ ‡åŒ…æ‹¬ï¼š
    - AP (IoU=0.50:0.95): ä¸»æŒ‡æ ‡ï¼ŒIoUé˜ˆå€¼0.5-0.95å¹³å‡
    - AP50: IoUé˜ˆå€¼0.5æ—¶çš„AP
    - AP75: IoUé˜ˆå€¼0.75æ—¶çš„AP  
    - APsmall/APmedium/APlarge: ä¸åŒå°ºå¯¸å¯¹è±¡çš„AP
    - AR1/AR10/AR100: ä¸åŒæ£€æµ‹é™åˆ¶ä¸‹çš„å¹³å‡å¬å›ç‡
    - ARsmall/ARmedium/ARlarge: ä¸åŒå°ºå¯¸å¯¹è±¡çš„AR
    """

    def __init__(self, dataloader=None, save_dir=None, pbar=None, args=None, _callbacks=None):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€COCOéªŒè¯å™¨ã€‚

        Args:
            dataloader: æ•°æ®åŠ è½½å™¨
            save_dir: ä¿å­˜ç›®å½•
            pbar: è¿›åº¦æ¡ï¼ˆå½“å‰é¡¹ç›®ä¸æ”¯æŒï¼Œå¿½ç•¥ï¼‰
            args: å‚æ•°é…ç½®ï¼ˆæ”¯æŒmodalityå‚æ•°ç”¨äºå•æ¨¡æ€éªŒè¯ï¼‰
            _callbacks: å›è°ƒå‡½æ•°
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–ï¼Œè·å¾—å®Œæ•´çš„å¤šæ¨¡æ€èƒ½åŠ›
        super().__init__(dataloader, save_dir, pbar, args, _callbacks)
        
        # COCOè¯„ä¼°å™¨å°†åœ¨init_metricsä¸­åˆå§‹åŒ–
        self.coco_metrics = None
        
        # å­˜å‚¨ç”¨äºCOCOè¯„ä¼°çš„è¾¹ç•Œæ¡†ä¿¡æ¯
        self.coco_stats = []
        
        # è¿›åº¦æ˜¾ç¤ºç›¸å…³
        self.total_batches = len(dataloader) if dataloader else 0
        self.current_batch = 0
        self.progress_bar = None
        
        # ä¿å­˜éªŒè¯å›¾åƒæ•°é‡
        self.num_images_processed = 0
        
        # é€Ÿåº¦ç»Ÿè®¡ä¿¡æ¯
        self.speed = {'preprocess': 0.0, 'inference': 0.0, 'loss': 0.0, 'postprocess': 0.0}
        self.times = []
        
        # æ—¥å¿—è¾“å‡º
        if self.modality:
            LOGGER.info(f"åˆå§‹åŒ–MultiModalCOCOValidator - å•æ¨¡æ€COCOéªŒè¯: {self.modality}-only")
        else:
            LOGGER.info("åˆå§‹åŒ–MultiModalCOCOValidator - åŒæ¨¡æ€COCOéªŒè¯")

    def init_metrics(self, model):
        """
        åˆå§‹åŒ–COCOè¯„ä¼°æŒ‡æ ‡ã€‚
        
        é¦–å…ˆè°ƒç”¨çˆ¶ç±»çš„init_metricsæ–¹æ³•ä»¥åˆå§‹åŒ–æ ‡å‡†çš„metricså¯¹è±¡ï¼Œ
        ç„¶ååˆå§‹åŒ–COCOMetricsä»¥æä¾›é¢å¤–çš„COCOæ ¼å¼è¯„ä¼°ã€‚
        
        Args:
            model: å¾…è¯„ä¼°çš„æ¨¡å‹
        """
        # Store the model reference for parameter counting in _print_overall_metrics
        self.model = model
        
        # è°ƒç”¨çˆ¶ç±»çš„init_metricsæ–¹æ³•ï¼Œåˆå§‹åŒ–æ ‡å‡†çš„DetMetrics
        # è¿™ç¡®ä¿äº†æ‰€æœ‰çˆ¶ç±»çš„è¯„ä¼°é€»è¾‘éƒ½èƒ½æ­£å¸¸å·¥ä½œ
        super().init_metrics(model)
        
        # æ¸…ç†ç´¯ç§¯æ•°æ®ï¼ˆé‡è¦ï¼šç¡®ä¿æ¯æ¬¡éªŒè¯å¼€å§‹æ—¶æ•°æ®æ˜¯å¹²å‡€çš„ï¼‰
        self.image_ori_shapes = []
        self.all_pred_boxes = []
        self.all_target_boxes = []
        self.all_pred_cls = []
        self.all_target_cls = []
        self.pred_to_img = []
        self.target_to_img = []
        
        # åˆå§‹åŒ–COCOè¯„ä¼°å™¨
        self.coco_metrics = COCOMetrics(
            save_dir=self.save_dir,
            names=getattr(model, 'names', {}),
            plot=self.args.plots if hasattr(self.args, 'plots') else False,
            on_plot=getattr(self, 'on_plot', None)
        )
        
        # æ¸…ç©ºCOCOç»Ÿè®¡ä¿¡æ¯
        self.coco_stats = []
        
        # ç¡®ä¿å±æ€§è¢«æ­£ç¡®è®¾ç½®ï¼ˆè¿™äº›å¯èƒ½å·²ç»åœ¨çˆ¶ç±»ä¸­è®¾ç½®ï¼‰
        if not hasattr(self, 'nc'):
            self.nc = getattr(model, 'nc', len(getattr(model, 'names', {})))
        if not hasattr(self, 'end2end'):
            self.end2end = getattr(model, "end2end", False)
        if not hasattr(self, 'names'):
            self.names = getattr(model, 'names', {})
        if not hasattr(self, 'seen'):
            self.seen = 0
        if not hasattr(self, 'jdict'):
            self.jdict = []
        
        LOGGER.info(f"åˆå§‹åŒ–COCOè¯„ä¼°æŒ‡æ ‡ - ç±»åˆ«æ•°: {self.nc}")

    def get_desc(self):
        """
        è¿”å›COCOæ ¼å¼çš„è¿›åº¦æ¡æè¿°ã€‚
        
        æä¾›æ¯”æ ‡å‡†éªŒè¯å™¨æ›´è¯¦ç»†çš„æè¿°ï¼Œçªå‡ºCOCOè¯„ä¼°ç‰¹æ€§ã€‚
        
        Returns:
            str: è¿›åº¦æ¡æè¿°å­—ç¬¦ä¸²
        """
        if self.modality:
            return f"%22s" + "%11s" * 5 % ("Class", "Images", "Instances", f"{self.modality.upper()}", "COCO-mAP@.5:.95")
        else:
            return f"%22s" + "%11s" * 5 % ("Class", "Images", "Instances", "RGB+X", "COCO-mAP@.5:.95")

    def update_metrics(self, preds, batch):
        """
        æ›´æ–°éªŒè¯æŒ‡æ ‡ï¼Œå¤ç”¨çˆ¶ç±»çš„è¯„ä¼°é€»è¾‘å¹¶æ”¶é›†COCOè¯„ä¼°æ‰€éœ€çš„æ•°æ®ã€‚
        
        é€šè¿‡è°ƒç”¨çˆ¶ç±»çš„update_metricsæ–¹æ³•ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨å·²ç»éªŒè¯è¿‡çš„IoUè®¡ç®—ã€
        true positiveåˆ¤æ–­ç­‰æ ¸å¿ƒè¯„ä¼°é€»è¾‘ï¼Œç„¶åä»çˆ¶ç±»çš„metricsä¸­æå–æ•°æ®ç”¨äºCOCOè¯„ä¼°ã€‚
        
        Args:
            preds: æ¨¡å‹é¢„æµ‹ç»“æœ
            batch: æ‰¹æ¬¡æ•°æ®ï¼ŒåŒ…å«å›¾åƒå’Œæ ‡ç­¾ä¿¡æ¯
        """
        # æ›´æ–°å½“å‰æ‰¹æ¬¡è®¡æ•°å¹¶æ˜¾ç¤ºè¿›åº¦
        self.current_batch += 1
        if self.progress_bar is not None:
            self.progress_bar.update(1)
            self.progress_bar.set_description(f"éªŒè¯æ‰¹æ¬¡ {self.current_batch}/{self.total_batches}")
        
        # åˆå§‹åŒ–ç´¯ç§¯æ•°æ®å®¹å™¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
        if not hasattr(self, 'image_ori_shapes'):
            self.image_ori_shapes = []  # æ¯ä¸ªå›¾åƒçš„åŸå§‹å°ºå¯¸
            self.all_pred_boxes = []
            self.all_target_boxes = []
            self.all_pred_cls = []
            self.all_target_cls = []
            self.pred_to_img = []  # è®°å½•æ¯ä¸ªé¢„æµ‹æ¡†å±äºå“ªä¸ªå›¾åƒ
            self.target_to_img = []  # è®°å½•æ¯ä¸ªçœŸå®æ¡†å±äºå“ªä¸ªå›¾åƒ
        
        # è°ƒç”¨çˆ¶ç±»çš„update_metricsæ–¹æ³•ï¼Œè®©çˆ¶ç±»å¤„ç†æ‰€æœ‰çš„è¯„ä¼°é€»è¾‘
        # è¿™åŒ…æ‹¬IoUè®¡ç®—ã€true positiveåˆ¤æ–­ã€metricsæ›´æ–°ç­‰
        super().update_metrics(preds, batch)
        
        # æ”¶é›†æ¯ä¸ªå›¾åƒçš„æ•°æ®ç”¨äºCOCO size-specificæŒ‡æ ‡è®¡ç®—
        for si, pred in enumerate(preds):
            # ä¿å­˜åŸå§‹å›¾åƒå°ºå¯¸ï¼ˆæ¯ä¸ªå›¾åƒä¸€ä¸ªï¼‰
            ori_shape = batch["ori_shape"][si]
            self.image_ori_shapes.append(ori_shape)
            
            # å½“å‰å·²å¤„ç†çš„å›¾åƒç´¢å¼•
            img_idx = len(self.image_ori_shapes) - 1
            
            # æ”¶é›†é¢„æµ‹æ¡†æ•°æ®
            if len(pred['bboxes']) > 0:
                # é¢„æµ‹æ¡†å·²ç»æ˜¯xyxyæ ¼å¼
                for i in range(len(pred['bboxes'])):
                    self.all_pred_boxes.append(pred['bboxes'][i].cpu().numpy())
                    self.all_pred_cls.append(pred['cls'][i].cpu().numpy())
                    self.pred_to_img.append(img_idx)  # è®°å½•æ¡†å±äºå“ªä¸ªå›¾åƒ
            
            # æ”¶é›†çœŸå®æ¡†æ•°æ®
            idx = batch["batch_idx"] == si
            target_bboxes = batch["bboxes"][idx]  # xywhæ ¼å¼ï¼Œå½’ä¸€åŒ–åæ ‡
            target_cls = batch["cls"][idx].squeeze(-1)
            
            if len(target_bboxes) > 0:
                # è½¬æ¢ä¸ºxyxyæ ¼å¼
                imgsz = batch["img"].shape[2:]
                target_bboxes_xyxy = ops.xywh2xyxy(target_bboxes) * torch.tensor(imgsz, device=self.device)[[1, 0, 1, 0]]
                
                # è®°å½•æ¯ä¸ªçœŸå®æ¡†
                for i in range(len(target_bboxes)):
                    self.all_target_boxes.append(target_bboxes_xyxy[i].cpu().numpy())
                    self.all_target_cls.append(target_cls[i].cpu().numpy())
                    self.target_to_img.append(img_idx)  # è®°å½•æ¡†å±äºå“ªä¸ªå›¾åƒ
    
    def update_speed_stats(self, preprocess_time=None, inference_time=None, postprocess_time=None, total_time=None):
        """
        æ›´æ–°é€Ÿåº¦ç»Ÿè®¡ä¿¡æ¯ã€‚
        
        Args:
            preprocess_time: é¢„å¤„ç†æ—¶é—´(ms)
            inference_time: æ¨ç†æ—¶é—´(ms)  
            postprocess_time: åå¤„ç†æ—¶é—´(ms)
            total_time: æ€»æ—¶é—´(ms)
        """
        if preprocess_time is not None:
            self.speed['preprocess'] = preprocess_time
        if inference_time is not None:
            self.speed['inference'] = inference_time
        if postprocess_time is not None:
            self.speed['postprocess'] = postprocess_time
        if total_time is not None:
            self.times.append(total_time)

    def print_results(self):
        """
        è¾“å‡ºCOCOè¯„ä¼°ç»“æœï¼ŒåŒ…æ‹¬å„ç±»åˆ«APæŒ‡æ ‡å’Œæ€»ä½“æ€§èƒ½æŒ‡æ ‡ã€‚
        """
        if self.coco_metrics is None:
            LOGGER.warning("COCOæŒ‡æ ‡å°šæœªåˆå§‹åŒ–ï¼Œæ— æ³•è¾“å‡ºç»“æœ")
            return
        
        # æ ‡é¢˜æ˜¾ç¤º
        print(f"\n{colorstr('blue', 'bold', '=' * 80)}")
        print(f"{colorstr('blue', 'bold', 'å¤šæ¨¡æ€COCOè¯„ä¼°ç»“æœ')}")
        print(f"{colorstr('blue', 'bold', '=' * 80)}")
        
        # æ¨¡æ€ä¿¡æ¯æ˜¾ç¤º
        if self.modality:
            print(f"éªŒè¯æ¨¡å¼: {colorstr('cyan', f'{self.modality.upper()}-only')} (å•æ¨¡æ€éªŒè¯)")
        else:
            print(f"éªŒè¯æ¨¡å¼: {colorstr('cyan', 'RGB+X')} (åŒæ¨¡æ€éªŒè¯)")
        
        print(f"æ•°æ®é›†: {getattr(self.args, 'data', 'N/A')}")
        print(f"ç±»åˆ«æ•°: {self.nc}")
        print(f"éªŒè¯å›¾åƒæ•°: {self.num_images_processed}")
        
        # å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡
        self._print_class_metrics()
        
        # æ€»ä½“æ€§èƒ½æŒ‡æ ‡
        self._print_overall_metrics()
        
        # é€Ÿåº¦ç»Ÿè®¡
        self._print_speed_stats()
        
        print(f"{colorstr('blue', 'bold', '=' * 80)}")
        
        # è‡ªåŠ¨ä¿å­˜CSVç»“æœ
        self._save_csv_results()
    
    def _print_table(self, table_data):
        """
        æ‰“å°æ ¼å¼åŒ–çš„è¡¨æ ¼ã€‚
        
        Args:
            table_data: è¡¨æ ¼æ•°æ®ï¼Œç¬¬ä¸€è¡Œä¸ºè¡¨å¤´
        """
        if not table_data:
            return
        
        # è®¡ç®—æ¯åˆ—çš„æœ€å¤§å®½åº¦
        col_widths = []
        for col_idx in range(len(table_data[0])):
            max_width = max(len(str(row[col_idx])) for row in table_data)
            col_widths.append(max_width + 2)  # æ·»åŠ 2ä¸ªå­—ç¬¦çš„è¾¹è·
        
        # æ‰“å°è¡¨å¤´
        header = table_data[0]
        print("â”Œ" + "â”¬".join("â”€" * width for width in col_widths) + "â”")
        print("â”‚" + "â”‚".join(f"{str(header[i]):<{col_widths[i]}}" for i in range(len(header))) + "â”‚")
        print("â”œ" + "â”¼".join("â”€" * width for width in col_widths) + "â”¤")
        
        # æ‰“å°æ•°æ®è¡Œ
        for row in table_data[1:]:
            print("â”‚" + "â”‚".join(f"{str(row[i]):<{col_widths[i]}}" for i in range(len(row))) + "â”‚")
        
        print("â””" + "â”´".join("â”€" * width for width in col_widths) + "â”˜")
    
    def _print_speed_stats(self):
        """
        æ‰“å°é€Ÿåº¦ç»Ÿè®¡ä¿¡æ¯ã€‚
        """
        print(f"\n{colorstr('cyan', 'bold', 'é€Ÿåº¦ç»Ÿè®¡')}")
        print(f"{colorstr('cyan', 'bold', '-' * 30)}")
        
        if self.times:
            avg_time = np.mean(self.times)
            print(f"å¹³å‡æ¯å¼ å›¾åƒå¤„ç†æ—¶é—´: {avg_time:.1f}ms")
            print(f"æ¨ç†é€Ÿåº¦: {1000/avg_time:.1f} FPS")
        
        if any(self.speed.values()):
            print(f"é¢„å¤„ç†: {self.speed['preprocess']:.1f}ms")
            print(f"æ¨ç†: {self.speed['inference']:.1f}ms") 
            print(f"åå¤„ç†: {self.speed['postprocess']:.1f}ms")
    
    def _print_class_metrics(self):
        """
        æ‰“å°æ¯ä¸ªç±»åˆ«çš„APæŒ‡æ ‡ï¼Œä½¿ç”¨è¡¨æ ¼æ ¼å¼ã€‚
        """
        print(f"\n{colorstr('green', 'bold', 'å„ç±»åˆ«COCOæŒ‡æ ‡')}")
        
        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        table_data = [["Class", "AP", "AP50", "AP75"]]  # è¡¨å¤´
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¯ä¸ªç±»åˆ«çš„ç»Ÿè®¡ä¿¡æ¯
        # COCOMetricsç°åœ¨å°†ç±»åˆ«çº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯å­˜å‚¨åœ¨class_statså±æ€§ä¸­
        if hasattr(self.coco_metrics, 'class_stats') and self.coco_metrics.class_stats and 'ap' in self.coco_metrics.class_stats:
            ap_array = self.coco_metrics.class_stats['ap']  # Shape: (n_classes, n_iou_thresholds)
            unique_classes = self.coco_metrics.class_stats['unique_classes']
            
            # è·å–IoUé˜ˆå€¼ç´¢å¼• (COCOæ ‡å‡†: 0.5:0.05:0.95)
            # ç¬¬0ä¸ªæ˜¯0.5, ç¬¬5ä¸ªæ˜¯0.75
            iou_50_idx = 0
            iou_75_idx = 5
            
            # æ”¶é›†æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡
            for ci, class_idx in enumerate(unique_classes):
                class_idx = int(class_idx)  # ç¡®ä¿æ˜¯æ•´æ•°
                if class_idx < len(self.names):
                    class_name = self.names[class_idx]
                else:
                    class_name = f"class_{class_idx}"
                
                # è·å–è¯¥ç±»åˆ«çš„APå€¼
                if ci < ap_array.shape[0]:
                    ap = float(ap_array[ci].mean())  # AP@0.5:0.95
                    ap50 = float(ap_array[ci, iou_50_idx]) if iou_50_idx < ap_array.shape[1] else 0
                    ap75 = float(ap_array[ci, iou_75_idx]) if iou_75_idx < ap_array.shape[1] else 0
                else:
                    ap = ap50 = ap75 = 0
                
                # æ·»åŠ åˆ°è¡¨æ ¼æ•°æ®ï¼Œæ ¼å¼åŒ–æ•°å€¼ä¸º3ä½å°æ•°
                table_data.append([class_name, f"{ap:.3f}", f"{ap50:.3f}", f"{ap75:.3f}"])
            
            # ä½¿ç”¨è¡¨æ ¼æ‰“å°
            self._print_table(table_data)
        else:
            # å¦‚æœæ²¡æœ‰è¯¦ç»†çš„ç±»åˆ«ç»Ÿè®¡ï¼Œå°è¯•ä»çˆ¶ç±»metricsè·å–åŸºæœ¬ä¿¡æ¯
            if hasattr(self.metrics, 'box') and hasattr(self.metrics.box, 'ap_class_index'):
                # ä½¿ç”¨çˆ¶ç±»çš„æ ‡å‡†æŒ‡æ ‡
                ap_class_index = self.metrics.box.ap_class_index
                table_data = [["Class", "AP", "AP50", "AP75"]]  # è¡¨å¤´
                
                # æ”¶é›†æœ‰æ•°æ®çš„ç±»åˆ«æŒ‡æ ‡
                for i, c in enumerate(ap_class_index):
                    class_name = self.names[c] if c < len(self.names) else f"class_{c}"
                    
                    # ä½¿ç”¨çˆ¶ç±»çš„æŒ‡æ ‡
                    p, r, ap50, ap = self.metrics.box.class_result(i)
                    ap75 = 0  # çˆ¶ç±»æ²¡æœ‰AP75
                    
                    # æ·»åŠ åˆ°è¡¨æ ¼æ•°æ®
                    table_data.append([class_name, f"{ap:.3f}", f"{ap50:.3f}", f"{ap75:.3f}"])
                
                # ä½¿ç”¨è¡¨æ ¼æ‰“å°
                self._print_table(table_data)
            else:
                print("\næ¯ç±»åˆ«æŒ‡æ ‡è¯¦æƒ…æš‚ä¸å¯ç”¨")
    
    def _print_overall_metrics(self):
        """
        æ‰“å°æ€»ä½“æ€§èƒ½æŒ‡æ ‡è¡¨ï¼ŒåŒ…æ‹¬APã€APsmall/medium/largeã€FPSã€å‚æ•°é‡ç­‰ã€‚
        """
        print(f"\n{colorstr('cyan', 'bold', 'æ€»ä½“æ€§èƒ½æŒ‡æ ‡')}")
        
        # è®¡ç®—FPS
        fps = 0.0
        if any(self.speed.values()):
            total_time = self.speed['preprocess'] + self.speed['inference'] + self.speed['postprocess']
            if total_time > 0:
                fps = 1000.0 / total_time
        
        # è·å–æ¨¡å‹å‚æ•°é‡
        params = 0
        if hasattr(self, 'model') and self.model is not None:
            try:
                # å°è¯•ä»modelè·å–å‚æ•°ä¿¡æ¯
                if hasattr(self.model, 'parameters'):
                    params = sum(p.numel() for p in self.model.parameters())
                elif hasattr(self.model, 'model') and hasattr(self.model.model, 'parameters'):
                    params = sum(p.numel() for p in self.model.model.parameters())
            except:
                params = 0
        
        # åˆ›å»ºæ€»ä½“æŒ‡æ ‡è¡¨æ ¼
        overall_table = [
            ["Metric", "AP", "AP50", "AP75", "APsmall", "APmedium", "APlarge", "FPS", "Params"],
            [
                "All",
                f"{self.coco_metrics.AP:.3f}",
                f"{self.coco_metrics.AP50:.3f}",
                f"{self.coco_metrics.AP75:.3f}",
                f"{getattr(self.coco_metrics, 'APsmall', 0.0):.3f}",
                f"{getattr(self.coco_metrics, 'APmedium', 0.0):.3f}",
                f"{getattr(self.coco_metrics, 'APlarge', 0.0):.3f}",
                f"{fps:.1f}",
                f"{params:,}" if params > 0 else "N/A"
            ]
        ]
        
        self._print_table(overall_table)
        
        # æ–°å¢ï¼šæŒ‰å°ºå¯¸æ€§èƒ½æŒ‡æ ‡è¡¨æ ¼
        print(f"\n{colorstr('yellow', 'bold', 'æŒ‰å°ºå¯¸æ€§èƒ½æŒ‡æ ‡')}")
        size_metrics_table = [
            ["Size", "AP", "AP50", "AP75"],
            [
                "Small", 
                f"{getattr(self.coco_metrics, 'APsmall', 0.0):.3f}",
                f"{getattr(self.coco_metrics, 'APsmall50', 0.0):.3f}",
                f"{getattr(self.coco_metrics, 'APsmall75', 0.0):.3f}"
            ],
            [
                "Medium", 
                f"{getattr(self.coco_metrics, 'APmedium', 0.0):.3f}",
                f"{getattr(self.coco_metrics, 'APmedium50', 0.0):.3f}",
                f"{getattr(self.coco_metrics, 'APmedium75', 0.0):.3f}"
            ],
            [
                "Large", 
                f"{getattr(self.coco_metrics, 'APlarge', 0.0):.3f}",
                f"{getattr(self.coco_metrics, 'APlarge50', 0.0):.3f}",
                f"{getattr(self.coco_metrics, 'APlarge75', 0.0):.3f}"
            ]
        ]
        self._print_table(size_metrics_table)
    
    def _save_csv_results(self):
        """
        è‡ªåŠ¨ä¿å­˜COCOéªŒè¯ç»“æœåˆ°CSVæ–‡ä»¶ã€‚
        ç”Ÿæˆ4ä¸ªCSVæ–‡ä»¶ï¼š
        - coco_metrics_by_class.csv: æŒ‰ç±»åˆ«çš„æŒ‡æ ‡
        - coco_metrics_by_size.csv: æŒ‰å°ºå¯¸çš„æŒ‡æ ‡  
        - coco_metrics_overall.csv: æ€»ä½“æŒ‡æ ‡
        - coco_metrics_comprehensive.csv: ç»¼åˆæ‰€æœ‰ä¿¡æ¯
        """
        try:
            # ç¡®ä¿ä¿å­˜ç›®å½•å­˜åœ¨
            save_dir = Path(self.save_dir)
            save_dir.mkdir(parents=True, exist_ok=True)
            
            # 1. æŒ‰ç±»åˆ«æŒ‡æ ‡CSV
            class_csv_path = save_dir / "coco_metrics_by_class.csv"
            with open(class_csv_path, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['Class', 'AP', 'AP50', 'AP75']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ¯ä¸ªç±»åˆ«çš„ç»Ÿè®¡ä¿¡æ¯
                if hasattr(self.coco_metrics, 'class_stats') and self.coco_metrics.class_stats and 'ap' in self.coco_metrics.class_stats:
                    ap_array = self.coco_metrics.class_stats['ap']
                    unique_classes = self.coco_metrics.class_stats['unique_classes']
                    
                    iou_50_idx = 0
                    iou_75_idx = 5
                    
                    for ci, class_idx in enumerate(unique_classes):
                        class_idx = int(class_idx)
                        class_name = self.names[class_idx] if class_idx < len(self.names) else f"class_{class_idx}"
                        
                        if ci < ap_array.shape[0]:
                            ap = float(ap_array[ci].mean())
                            ap50 = float(ap_array[ci, iou_50_idx]) if iou_50_idx < ap_array.shape[1] else 0
                            ap75 = float(ap_array[ci, iou_75_idx]) if iou_75_idx < ap_array.shape[1] else 0
                        else:
                            ap = ap50 = ap75 = 0
                        
                        writer.writerow({
                            'Class': class_name,
                            'AP': f"{ap:.3f}",
                            'AP50': f"{ap50:.3f}",
                            'AP75': f"{ap75:.3f}"
                        })
                elif hasattr(self.metrics, 'box') and hasattr(self.metrics.box, 'ap_class_index'):
                    # ä½¿ç”¨çˆ¶ç±»çš„æ ‡å‡†æŒ‡æ ‡
                    ap_class_index = self.metrics.box.ap_class_index
                    for i, c in enumerate(ap_class_index):
                        class_name = self.names[c] if c < len(self.names) else f"class_{c}"
                        p, r, ap50, ap = self.metrics.box.class_result(i)
                        writer.writerow({
                            'Class': class_name,
                            'AP': f"{ap:.3f}",
                            'AP50': f"{ap50:.3f}",
                            'AP75': "0.000"  # çˆ¶ç±»æ²¡æœ‰AP75
                        })
            
            # 2. æŒ‰å°ºå¯¸æŒ‡æ ‡CSV
            size_csv_path = save_dir / "coco_metrics_by_size.csv"
            with open(size_csv_path, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['Size', 'AP', 'AP50', 'AP75']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                sizes = ['Small', 'Medium', 'Large']
                for size in sizes:
                    ap = getattr(self.coco_metrics, f'AP{size.lower()}', 0.0)
                    ap50 = getattr(self.coco_metrics, f'AP{size.lower()}50', 0.0)
                    ap75 = getattr(self.coco_metrics, f'AP{size.lower()}75', 0.0)
                    
                    writer.writerow({
                        'Size': size,
                        'AP': f"{ap:.3f}",
                        'AP50': f"{ap50:.3f}",
                        'AP75': f"{ap75:.3f}"
                    })
            
            # 3. æ€»ä½“æŒ‡æ ‡CSV
            overall_csv_path = save_dir / "coco_metrics_overall.csv"
            with open(overall_csv_path, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['Metric', 'Value']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                # è®¡ç®—FPSå’Œå‚æ•°é‡
                fps = 0.0
                if any(self.speed.values()):
                    total_time = self.speed['preprocess'] + self.speed['inference'] + self.speed['postprocess']
                    if total_time > 0:
                        fps = 1000.0 / total_time
                
                params = 0
                if hasattr(self, 'model') and self.model is not None:
                    try:
                        if hasattr(self.model, 'parameters'):
                            params = sum(p.numel() for p in self.model.parameters())
                        elif hasattr(self.model, 'model') and hasattr(self.model.model, 'parameters'):
                            params = sum(p.numel() for p in self.model.model.parameters())
                    except:
                        params = 0
                
                # å†™å…¥æ€»ä½“æŒ‡æ ‡
                metrics_data = [
                    ('AP', f"{self.coco_metrics.AP:.3f}"),
                    ('AP50', f"{self.coco_metrics.AP50:.3f}"),
                    ('AP75', f"{self.coco_metrics.AP75:.3f}"),
                    ('APsmall', f"{getattr(self.coco_metrics, 'APsmall', 0.0):.3f}"),
                    ('APmedium', f"{getattr(self.coco_metrics, 'APmedium', 0.0):.3f}"),
                    ('APlarge', f"{getattr(self.coco_metrics, 'APlarge', 0.0):.3f}"),
                    ('FPS', f"{fps:.1f}"),
                    ('Parameters', str(params) if params > 0 else "N/A"),
                    ('Images', str(self.num_images_processed)),
                    ('Modality', self.modality if self.modality else 'multimodal')
                ]
                
                for metric, value in metrics_data:
                    writer.writerow({'Metric': metric, 'Value': value})
            
            # 4. ç»¼åˆä¿¡æ¯CSV
            comprehensive_csv_path = save_dir / "coco_metrics_comprehensive.csv"
            with open(comprehensive_csv_path, 'w', newline='', encoding='utf-8') as csvfile:
                fieldnames = ['Category', 'Type', 'Metric', 'Value']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                # å†™å…¥ç±»åˆ«æŒ‡æ ‡
                if hasattr(self.coco_metrics, 'class_stats') and self.coco_metrics.class_stats and 'ap' in self.coco_metrics.class_stats:
                    ap_array = self.coco_metrics.class_stats['ap']
                    unique_classes = self.coco_metrics.class_stats['unique_classes']
                    
                    iou_50_idx = 0
                    iou_75_idx = 5
                    
                    for ci, class_idx in enumerate(unique_classes):
                        class_idx = int(class_idx)
                        class_name = self.names[class_idx] if class_idx < len(self.names) else f"class_{class_idx}"
                        
                        if ci < ap_array.shape[0]:
                            ap = float(ap_array[ci].mean())
                            ap50 = float(ap_array[ci, iou_50_idx]) if iou_50_idx < ap_array.shape[1] else 0
                            ap75 = float(ap_array[ci, iou_75_idx]) if iou_75_idx < ap_array.shape[1] else 0
                        else:
                            ap = ap50 = ap75 = 0
                        
                        writer.writerow({'Category': class_name, 'Type': 'Class', 'Metric': 'AP', 'Value': f"{ap:.3f}"})
                        writer.writerow({'Category': class_name, 'Type': 'Class', 'Metric': 'AP50', 'Value': f"{ap50:.3f}"})
                        writer.writerow({'Category': class_name, 'Type': 'Class', 'Metric': 'AP75', 'Value': f"{ap75:.3f}"})
                
                # å†™å…¥å°ºå¯¸æŒ‡æ ‡
                sizes = ['Small', 'Medium', 'Large']
                for size in sizes:
                    ap = getattr(self.coco_metrics, f'AP{size.lower()}', 0.0)
                    ap50 = getattr(self.coco_metrics, f'AP{size.lower()}50', 0.0)
                    ap75 = getattr(self.coco_metrics, f'AP{size.lower()}75', 0.0)
                    
                    writer.writerow({'Category': size, 'Type': 'Size', 'Metric': 'AP', 'Value': f"{ap:.3f}"})
                    writer.writerow({'Category': size, 'Type': 'Size', 'Metric': 'AP50', 'Value': f"{ap50:.3f}"})
                    writer.writerow({'Category': size, 'Type': 'Size', 'Metric': 'AP75', 'Value': f"{ap75:.3f}"})
                
                # å†™å…¥æ€»ä½“æŒ‡æ ‡
                writer.writerow({'Category': 'Overall', 'Type': 'Summary', 'Metric': 'AP', 'Value': f"{self.coco_metrics.AP:.3f}"})
                writer.writerow({'Category': 'Overall', 'Type': 'Summary', 'Metric': 'AP50', 'Value': f"{self.coco_metrics.AP50:.3f}"})
                writer.writerow({'Category': 'Overall', 'Type': 'Summary', 'Metric': 'AP75', 'Value': f"{self.coco_metrics.AP75:.3f}"})
                writer.writerow({'Category': 'Overall', 'Type': 'Summary', 'Metric': 'APsmall', 'Value': f"{getattr(self.coco_metrics, 'APsmall', 0.0):.3f}"})
                writer.writerow({'Category': 'Overall', 'Type': 'Summary', 'Metric': 'APmedium', 'Value': f"{getattr(self.coco_metrics, 'APmedium', 0.0):.3f}"})
                writer.writerow({'Category': 'Overall', 'Type': 'Summary', 'Metric': 'APlarge', 'Value': f"{getattr(self.coco_metrics, 'APlarge', 0.0):.3f}"})
                writer.writerow({'Category': 'Overall', 'Type': 'Summary', 'Metric': 'FPS', 'Value': f"{fps:.1f}"})
                writer.writerow({'Category': 'Overall', 'Type': 'Summary', 'Metric': 'Parameters', 'Value': str(params) if params > 0 else "N/A"})
                writer.writerow({'Category': 'Overall', 'Type': 'Summary', 'Metric': 'Images', 'Value': str(self.num_images_processed)})
                writer.writerow({'Category': 'Overall', 'Type': 'Summary', 'Metric': 'Modality', 'Value': self.modality if self.modality else 'multimodal'})
            
            LOGGER.info(f"CSVç»“æœå·²ä¿å­˜åˆ°: {save_dir}")
            LOGGER.info(f"  - {class_csv_path.name}")
            LOGGER.info(f"  - {size_csv_path.name}")
            LOGGER.info(f"  - {overall_csv_path.name}")
            LOGGER.info(f"  - {comprehensive_csv_path.name}")
            
        except Exception as e:
            LOGGER.warning(f"ä¿å­˜CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def get_stats(self):
        """
        ä»»åŠ¡2.6 - å®ç°get_statsæ–¹æ³•ï¼š
        - è¿”å›COCOæ ¼å¼çš„æŒ‡æ ‡å­—å…¸ï¼Œä½¿ç”¨'metrics/coco/'å‰ç¼€å‘½å
        - ç¡®ä¿ä¸ç°æœ‰YOLOéªŒè¯ç³»ç»Ÿçš„å…¼å®¹æ€§
        - åŒ…å«æ‰€æœ‰12ä¸ªCOCOæŒ‡æ ‡çš„é”®å€¼å¯¹
        - æ”¯æŒè®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡ç›‘æ§
        - è¿”å›æ ¼å¼è¦ä¸DetectionValidator.get_stats()å…¼å®¹
        
        Returns:
            dict: åŒ…å«COCOæŒ‡æ ‡çš„å­—å…¸ï¼Œé”®åä¸æ ‡å‡†æ ¼å¼å…¼å®¹
        """
        if self.coco_metrics is None:
            LOGGER.warning("COCOæŒ‡æ ‡å°šæœªåˆå§‹åŒ–ï¼Œè¿”å›ç©ºå­—å…¸")
            return {}
        
        # COCOæŒ‡æ ‡å·²åœ¨finalize_metricsä¸­è®¡ç®—å®Œæˆ
        
        # æ„å»ºå®Œæ•´çš„COCOæŒ‡æ ‡å­—å…¸
        stats = {
            # æ ‡å‡†YOLOå…¼å®¹æ ¼å¼ - ä¸»è¦æŒ‡æ ‡
            'metrics/precision(B)': getattr(self.coco_metrics, 'precision', 0.0),
            'metrics/recall(B)': getattr(self.coco_metrics, 'recall', 0.0),
            'metrics/mAP50(B)': getattr(self.coco_metrics, 'AP50', 0.0),
            'metrics/mAP50-95(B)': getattr(self.coco_metrics, 'AP', 0.0),
            
            # COCOç‰¹å®šæŒ‡æ ‡ - ä½¿ç”¨'metrics/coco/'å‰ç¼€
            'metrics/coco/AP': getattr(self.coco_metrics, 'AP', 0.0),
            'metrics/coco/AP50': getattr(self.coco_metrics, 'AP50', 0.0),
            'metrics/coco/AP75': getattr(self.coco_metrics, 'AP75', 0.0),
            'metrics/coco/APsmall': getattr(self.coco_metrics, 'APsmall', 0.0),
            'metrics/coco/APmedium': getattr(self.coco_metrics, 'APmedium', 0.0),
            'metrics/coco/APlarge': getattr(self.coco_metrics, 'APlarge', 0.0),
            'metrics/coco/AR1': getattr(self.coco_metrics, 'AR1', 0.0),
            'metrics/coco/AR10': getattr(self.coco_metrics, 'AR10', 0.0),
            'metrics/coco/AR100': getattr(self.coco_metrics, 'AR100', 0.0),
            'metrics/coco/ARsmall': getattr(self.coco_metrics, 'ARsmall', 0.0),
            'metrics/coco/ARmedium': getattr(self.coco_metrics, 'ARmedium', 0.0),
            'metrics/coco/ARlarge': getattr(self.coco_metrics, 'ARlarge', 0.0),
            
            # è®­ç»ƒå™¨å…¼å®¹æ€§æŒ‡æ ‡
            'fitness': getattr(self.coco_metrics, 'AP', 0.0),  # ä½¿ç”¨ä¸»æŒ‡æ ‡APä½œä¸ºfitness
            
            # é€Ÿåº¦æŒ‡æ ‡
            'val/speed_preprocess': self.speed.get('preprocess', 0.0),
            'val/speed_inference': self.speed.get('inference', 0.0),
            'val/speed_postprocess': self.speed.get('postprocess', 0.0),
            
            # æ•°æ®ç»Ÿè®¡
            'val/images': len(self.coco_stats),
            'val/instances': sum(len(stat.get('ground_truth_labels', [])) for stat in self.coco_stats),
        }
        
        # æ·»åŠ æ¨¡æ€ç‰¹å®šä¿¡æ¯
        if self.modality:
            stats[f'val/modality'] = self.modality
            stats[f'metrics/coco/modality'] = self.modality
        else:
            stats[f'val/modality'] = 'multimodal'
            stats[f'metrics/coco/modality'] = 'RGB+X'
        
        # æ·»åŠ æ¯ç±»åˆ«æŒ‡æ ‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(self.coco_metrics, 'per_class_metrics'):
            for class_id, class_metrics in self.coco_metrics.per_class_metrics.items():
                class_name = getattr(self.coco_metrics, 'names', {}).get(class_id, f'class_{class_id}')
                stats[f'metrics/coco/class_{class_name}_AP'] = class_metrics.get('AP', 0.0)
                stats[f'metrics/coco/class_{class_name}_AP50'] = class_metrics.get('AP50', 0.0)
                stats[f'metrics/coco/class_{class_name}_AP75'] = class_metrics.get('AP75', 0.0)
        
        return stats

    # åˆ é™¤äº†æ—§çš„_process_coco_statsæ–¹æ³•ï¼Œç°åœ¨ä½¿ç”¨_process_coco_stats_from_metrics
    
    def _set_default_coco_stats(self):
        """
        è®¾ç½®é»˜è®¤çš„COCOç»Ÿè®¡å€¼ã€‚
        """
        default_stats = {
            'AP': 0.0, 'AP50': 0.0, 'AP75': 0.0,
            'APsmall': 0.0, 'APmedium': 0.0, 'APlarge': 0.0,
            'AR1': 0.0, 'AR10': 0.0, 'AR100': 0.0,
            'ARsmall': 0.0, 'ARmedium': 0.0, 'ARlarge': 0.0
        }
        self.coco_metrics.update(default_stats)
    
    def _process_coco_stats_from_metrics(self):
        """
        ä»çˆ¶ç±»çš„metricsä¸­æå–æ•°æ®å¹¶è®¡ç®—COCOæŒ‡æ ‡ã€‚
        
        è¿™ä¸ªæ–¹æ³•ç›´æ¥ä½¿ç”¨çˆ¶ç±»å·²ç»è®¡ç®—å¥½çš„tpã€confç­‰æ•°æ®ï¼Œ
        è½¬æ¢æˆCOCOMetricsæ‰€éœ€çš„æ ¼å¼å¹¶è®¡ç®—COCOæŒ‡æ ‡ã€‚
        """
        try:
            # ä»çˆ¶ç±»çš„metricsä¸­æå–ç»Ÿè®¡æ•°æ®
            stats = self.metrics.stats
            
            # å°†åˆ—è¡¨è½¬æ¢ä¸ºnumpyæ•°ç»„
            tp = np.concatenate(stats['tp'], axis=0) if stats['tp'] else np.array([])
            conf = np.concatenate(stats['conf'], axis=0) if stats['conf'] else np.array([])
            pred_cls = np.concatenate(stats['pred_cls'], axis=0) if stats['pred_cls'] else np.array([])
            target_cls = np.concatenate(stats['target_cls'], axis=0) if stats['target_cls'] else np.array([])
            
            # å¤„ç†è¿‡å¤šçš„æ£€æµ‹ç»“æœ
            # COCOMetricså†…éƒ¨æœ‰ä¸€ä¸ªç¡¬ç¼–ç çš„1000ä¸ªæ£€æµ‹çš„é™åˆ¶
            # æˆ‘ä»¬éœ€è¦æŒ‰ç½®ä¿¡åº¦æ’åºå¹¶åªä¿ç•™å‰ N ä¸ªæ£€æµ‹
            MAX_DETECTIONS_PER_IMAGE = 100  # COCOæ ‡å‡†æ¯å¼ å›¾åƒæœ€å¤š100ä¸ªæ£€æµ‹
            
            if len(conf) > 0:
                # æŒ‰ç½®ä¿¡åº¦é™åºæ’åº
                sort_indices = np.argsort(conf)[::-1]
                
                # ä¸ºæ¯å¼ å›¾åƒé™åˆ¶æ£€æµ‹æ•°é‡
                # ç”±äºæˆ‘ä»¬æ²¡æœ‰å›¾åƒIDä¿¡æ¯ï¼Œè¿™é‡Œç®€å•åœ°é™åˆ¶æ€»æ•°
                # ä½¿ç”¨çˆ¶ç±»çš„seenå±æ€§æˆ–é»˜è®¤å€¼
                num_images = getattr(self, 'seen', 630) if hasattr(self, 'seen') else 630
                max_total_detections = MAX_DETECTIONS_PER_IMAGE * num_images
                
                # ä¸ºäº†é¿å…COCOMetricså†…éƒ¨çš„ç¡¬ç¼–ç é™åˆ¶ï¼Œè¿›ä¸€æ­¥é™åˆ¶æ€»æ•°
                max_total_detections = min(max_total_detections, 50000)  # é™åˆ¶æ€»æ•°ä¸º50000
                
                if len(sort_indices) > max_total_detections:
                    LOGGER.warning(f"æ£€æµ‹æ•°é‡({len(sort_indices)})è¶…è¿‡COCOé™åˆ¶({max_total_detections})ï¼Œå°†æŒ‰ç½®ä¿¡åº¦æˆªæ–­")
                    sort_indices = sort_indices[:max_total_detections]
                
                # æŒ‰æ’åºç´¢å¼•é‡æ–°æ’åˆ—æ‰€æœ‰æ•°æ®
                tp = tp[sort_indices] if tp.ndim > 1 else tp[sort_indices]
                conf = conf[sort_indices]
                pred_cls = pred_cls[sort_indices]
                # target_clsä¸éœ€è¦é‡æ–°æ’åºï¼Œå› ä¸ºå®ƒæ˜¯çœŸå®æ ‡ç­¾
            
            # è·å–bboxæ•°æ®ï¼ˆä½¿ç”¨æ”¶é›†çš„æ•°æ®ï¼‰
            pred_boxes = None
            target_boxes = None
            ori_shapes = None
            
            # ä½¿ç”¨åœ¨update_metricsä¸­æ”¶é›†çš„bboxå’Œå°ºå¯¸æ•°æ®
            pred_to_img = None
            target_to_img = None
            
            if hasattr(self, 'all_pred_boxes') and self.all_pred_boxes:
                pred_boxes = np.array(self.all_pred_boxes)
                pred_to_img = np.array(self.pred_to_img)
                # ç”±äºæˆ‘ä»¬åœ¨æ”¶é›†æ—¶å·²ç»æŒ‰æ£€æµ‹é¡ºåºå­˜å‚¨ï¼Œè¿™é‡Œéœ€è¦åŒ¹é…æ’åºåçš„ç´¢å¼•
                # ä½†ç”±äºpred_boxesæ˜¯æŒ‰æ£€æµ‹é¡ºåºæ”¶é›†çš„ï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿ä¸tp/confçš„é¡ºåºä¸€è‡´
                if len(conf) > 0 and len(sort_indices) < len(pred_boxes):
                    pred_boxes = pred_boxes[sort_indices]
                    pred_to_img = pred_to_img[sort_indices]
                    
            if hasattr(self, 'all_target_boxes') and self.all_target_boxes:
                target_boxes = np.array(self.all_target_boxes)
                target_to_img = np.array(self.target_to_img)
                
            if hasattr(self, 'image_ori_shapes') and self.image_ori_shapes:
                # ori_shapesæ˜¯æ¯ä¸ªå›¾åƒçš„åŸå§‹å°ºå¯¸åˆ—è¡¨
                ori_shapes = self.image_ori_shapes
            
            
            # è°ƒç”¨COCOMetrics.processè®¡ç®—COCOæŒ‡æ ‡
            self.coco_metrics.process(
                tp=tp,
                conf=conf,
                pred_cls=pred_cls,
                target_cls=target_cls,
                pred_boxes=pred_boxes,
                target_boxes=target_boxes,
                ori_shapes=ori_shapes
            )
            
            # COCOMetricsç°åœ¨ä¼šåœ¨class_statså±æ€§ä¸­ä¿å­˜ç±»åˆ«çº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯
            if hasattr(self.coco_metrics, 'class_stats') and self.coco_metrics.class_stats:
                LOGGER.info(f"COCOç±»åˆ«ç»Ÿè®¡å¯ç”¨: {list(self.coco_metrics.class_stats.keys())}")
            
            LOGGER.info(f"COCOæŒ‡æ ‡è®¡ç®—å®Œæˆ - å¤„ç†äº† {len(conf) if conf.size > 0 else 0} ä¸ªæ£€æµ‹ç»“æœ")
            
        except Exception as e:
            LOGGER.error(f"è®¡ç®—COCOæŒ‡æ ‡æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            self._set_default_coco_stats()
    
    def _preprocess_coco_data(self):
        """
        é¢„å¤„ç†COCOæ•°æ®ï¼Œä¼˜åŒ–æ‰¹é‡å¤„ç†ã€‚
        
        Returns:
            tuple: (all_predictions, all_ground_truths)
        """
        all_predictions = []
        all_ground_truths = []
        
        # ä½¿ç”¨å†…éƒ¨è¿›åº¦æ¡æ˜¾ç¤ºæ•°æ®å¤„ç†è¿›åº¦
        for stats in tqdm(self.coco_stats, desc="å¤„ç†å›¾åƒæ•°æ®", unit="å›¾åƒ", leave=False):
            image_id = stats['image_id']
            preds = stats['predictions']
            gt_labels = stats['ground_truth_labels']
            gt_bboxes = stats['ground_truth_bboxes']
            orig_shape = stats['original_shape']
            
            # æ‰¹é‡å¤„ç†é¢„æµ‹ç»“æœ
            if isinstance(preds, torch.Tensor) and len(preds) > 0:
                pred_data = self._process_predictions_batch(preds, image_id, orig_shape)
                all_predictions.extend(pred_data)
            
            # æ‰¹é‡å¤„ç†çœŸå®æ ‡ç­¾
            if isinstance(gt_labels, torch.Tensor) and len(gt_labels) > 0:
                gt_data = self._process_ground_truths_batch(gt_labels, gt_bboxes, image_id, orig_shape)
                all_ground_truths.extend(gt_data)
        
        return all_predictions, all_ground_truths
    
    def _process_predictions_batch(self, preds, image_id, orig_shape):
        """
        æ‰¹é‡å¤„ç†é¢„æµ‹ç»“æœï¼Œæé«˜æ•ˆç‡ã€‚
        
        Args:
            preds: é¢„æµ‹å¼ é‡
            image_id: å›¾åƒID
            orig_shape: åŸå§‹å›¾åƒå°ºå¯¸
            
        Returns:
            list: å¤„ç†åçš„é¢„æµ‹ç»“æœåˆ—è¡¨
        """
        predictions = []
        
        # å‘é‡åŒ–å¤„ç†é¢„æµ‹ç»“æœ
        if len(preds) > 0 and preds.shape[-1] >= 6:
            # æ‰¹é‡æå–æ•°æ®
            bboxes = preds[:, :4].cpu().numpy()  # [x1, y1, x2, y2]
            confs = preds[:, 4].cpu().numpy()    # ç½®ä¿¡åº¦
            classes = preds[:, 5].cpu().numpy().astype(int)  # ç±»åˆ«
            
            # æ‰¹é‡è®¡ç®—é¢ç§¯
            areas = np.array([COCOMetrics.calculate_bbox_area(bbox, orig_shape) for bbox in bboxes])
            
            # æ‰¹é‡æ„å»ºç»“æœ
            for i in range(len(preds)):
                predictions.append({
                    'image_id': image_id,
                    'bbox': bboxes[i],
                    'confidence': float(confs[i]),
                    'class': int(classes[i]),
                    'area': areas[i],
                    'original_shape': orig_shape
                })
        
        return predictions
    
    def _process_ground_truths_batch(self, gt_labels, gt_bboxes, image_id, orig_shape):
        """
        æ‰¹é‡å¤„ç†çœŸå®æ ‡ç­¾ï¼Œæé«˜æ•ˆç‡ã€‚
        
        Args:
            gt_labels: çœŸå®æ ‡ç­¾å¼ é‡
            gt_bboxes: çœŸå®è¾¹ç•Œæ¡†å¼ é‡
            image_id: å›¾åƒID
            orig_shape: åŸå§‹å›¾åƒå°ºå¯¸
            
        Returns:
            list: å¤„ç†åçš„çœŸå®æ ‡ç­¾åˆ—è¡¨
        """
        ground_truths = []
        
        if len(gt_labels) > 0 and len(gt_bboxes) > 0:
            # å‘é‡åŒ–å¤„ç†
            labels = gt_labels.cpu().numpy().astype(int)
            bboxes = gt_bboxes.cpu().numpy()
            
            # æ‰¹é‡è®¡ç®—é¢ç§¯
            areas = np.array([COCOMetrics.calculate_bbox_area(bbox, orig_shape) for bbox in bboxes])
            
            # æ‰¹é‡æ„å»ºç»“æœ
            for i in range(len(labels)):
                ground_truths.append({
                    'image_id': image_id,
                    'bbox': bboxes[i],
                    'class': int(labels[i]),
                    'area': areas[i],
                    'original_shape': orig_shape
                })
        
        return ground_truths
    
    def _compute_coco_metrics_optimized(self, predictions, ground_truths):
        """
        ä¼˜åŒ–çš„COCOæŒ‡æ ‡è®¡ç®—æ–¹æ³•ã€‚
        
        ä½¿ç”¨COCOMetricsç±»çš„ä¼˜åŒ–å¤„ç†æ–¹æ³•ã€‚
        
        Args:
            predictions: æ‰€æœ‰é¢„æµ‹ç»“æœåˆ—è¡¨
            ground_truths: æ‰€æœ‰çœŸå®æ ‡ç­¾åˆ—è¡¨
            
        Returns:
            dict: åŒ…å«12é¡¹COCOæŒ‡æ ‡çš„å­—å…¸
        """
        if len(predictions) == 0 or len(ground_truths) == 0:
            return {
                'AP': 0.0, 'AP50': 0.0, 'AP75': 0.0,
                'APsmall': 0.0, 'APmedium': 0.0, 'APlarge': 0.0,
                'AR1': 0.0, 'AR10': 0.0, 'AR100': 0.0,
                'ARsmall': 0.0, 'ARmedium': 0.0, 'ARlarge': 0.0
            }
        
        try:
            # è½¬æ¢æ•°æ®æ ¼å¼ä¸ºCOCOMetrics.process()æ‰€éœ€çš„æ ¼å¼
            tp, conf, pred_cls, target_cls, pred_boxes, target_boxes, ori_shapes = self._convert_to_coco_format(
                predictions, ground_truths
            )
            
            # ä½¿ç”¨COCOMetricsçš„ä¼˜åŒ–å¤„ç†æ–¹æ³•
            temp_metrics = COCOMetrics(save_dir=self.save_dir, names=self.coco_metrics.names)
            temp_metrics.process(
                tp, conf, pred_cls, target_cls,
                pred_boxes=pred_boxes, 
                target_boxes=target_boxes, 
                ori_shapes=ori_shapes,
                show_progress=True  # å¯ç”¨è¿›åº¦æ˜¾ç¤º
            )
            
            # è¿”å›è®¡ç®—å¾—åˆ°çš„æŒ‡æ ‡
            return temp_metrics.get_summary_dict()
            
        except Exception as e:
            LOGGER.error(f"COCOæŒ‡æ ‡è®¡ç®—å†…éƒ¨é”™è¯¯: {e}")
            return {
                'AP': 0.0, 'AP50': 0.0, 'AP75': 0.0,
                'APsmall': 0.0, 'APmedium': 0.0, 'APlarge': 0.0,
                'AR1': 0.0, 'AR10': 0.0, 'AR100': 0.0,
                'ARsmall': 0.0, 'ARmedium': 0.0, 'ARlarge': 0.0
            }
    
    def _convert_to_coco_format(self, predictions, ground_truths):
        """
        å°†é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾è½¬æ¢ä¸ºCOCOMetrics.process()æ‰€éœ€çš„æ ¼å¼ã€‚
        
        Args:
            predictions: é¢„æµ‹ç»“æœåˆ—è¡¨
            ground_truths: çœŸå®æ ‡ç­¾åˆ—è¡¨
            
        Returns:
            tuple: (tp, conf, pred_cls, target_cls, pred_boxes, target_boxes, ori_shapes)
        """
        # ç®€åŒ–å®ç°ï¼šåˆ›å»ºåŸºæœ¬çš„æ•°æ®æ ¼å¼
        if not predictions or not ground_truths:
            return (np.array([]), np.array([]), np.array([]), np.array([]), 
                   np.array([]).reshape(0, 4), np.array([]).reshape(0, 4), [])
        
        # æå–é¢„æµ‹æ•°æ®
        pred_confs = np.array([p['confidence'] for p in predictions])
        pred_classes = np.array([p['class'] for p in predictions])
        pred_boxes = np.array([p['bbox'] for p in predictions])
        
        # æå–çœŸå®æ ‡ç­¾æ•°æ®
        target_classes = np.array([gt['class'] for gt in ground_truths])
        target_boxes = np.array([gt['bbox'] for gt in ground_truths])
        
        # è·å–æ‰€æœ‰åŸå§‹å›¾åƒå°ºå¯¸
        ori_shapes = list(set([tuple(p['original_shape']) for p in predictions + ground_truths]))
        
        # ç®€åŒ–çš„TPè®¡ç®—ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„IoUåŒ¹é…ï¼‰
        # è¿™é‡Œä½¿ç”¨ç®€åŒ–çš„æ–¹æ³•ï¼Œå®é™…æ•ˆæœå¯èƒ½ä¸å¦‚å®Œæ•´çš„COCOè¯„ä¼°
        tp = np.ones((len(predictions), 10))  # å‡è®¾æ‰€æœ‰é¢„æµ‹éƒ½æ˜¯TP
        
        return tp, pred_confs, pred_classes, target_classes, pred_boxes, target_boxes, ori_shapes

    def run_validation(self):
        """
        è¿è¡Œå®Œæ•´çš„éªŒè¯æµç¨‹ï¼Œé›†æˆè¿›åº¦æ˜¾ç¤ºã€‚
        
        è¿™ä¸ªæ–¹æ³•é‡å†™äº†çˆ¶ç±»çš„éªŒè¯æµç¨‹ï¼Œæ·»åŠ äº†å®Œæ•´çš„è¿›åº¦æ˜¾ç¤ºæ”¯æŒã€‚
        """
        # åˆå§‹åŒ–è¿›åº¦æ¡
        self.init_progress_bar()
        
        try:
            # è°ƒç”¨çˆ¶ç±»çš„éªŒè¯æ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            # è¿™é‡Œå¯ä»¥è°ƒç”¨MultiModalDetectionValidatorçš„éªŒè¯æ–¹æ³•
            # æˆ–è€…å®ç°è‡ªå®šä¹‰çš„éªŒè¯æµç¨‹
            
            # å¦‚æœéœ€è¦è°ƒç”¨çˆ¶ç±»æ–¹æ³•ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„è¡Œ
            # super().run_validation()
            
            LOGGER.info("å¤šæ¨¡æ€COCOéªŒè¯æµç¨‹å®Œæˆ")
            
        finally:
            # ç¡®ä¿è¿›åº¦æ¡è¢«æ­£ç¡®å…³é—­
            self.close_progress_bar()

    def _extract_ori_shapes(self, batch, batch_size):
        """
        ä¼˜åŒ–åŸå§‹å›¾åƒå°ºå¯¸ä¿¡æ¯æå–ã€‚
        
        ç»Ÿä¸€å¤„ç†å¤šç§å¯èƒ½çš„ori_shapeæ ¼å¼ï¼š
        - åˆ—è¡¨/å…ƒç»„æ ¼å¼: [(h1,w1), (h2,w2), ...]
        - å¼ é‡æ ¼å¼: tensor([[h1,w1], [h2,w2], ...])
        - å•ä¸ªå°ºå¯¸: (h,w) æˆ– tensor([h,w])
        - å¤šæ¨¡æ€æ•°æ®çš„6é€šé“è¾“å…¥å…¼å®¹æ€§
        
        Args:
            batch: æ‰¹æ¬¡æ•°æ®
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            list: æ ‡å‡†åŒ–çš„åŸå§‹å°ºå¯¸åˆ—è¡¨
        """
        orig_shapes = batch.get("ori_shape", None)
        
        if orig_shapes is None:
            # å¦‚æœæ²¡æœ‰åŸå§‹å°ºå¯¸ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼
            LOGGER.warning(f"æ‰¹æ¬¡ç¼ºå°‘åŸå§‹å°ºå¯¸ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼ (640, 640)")
            return [(640, 640)] * batch_size
        
        # å¤„ç†å¼ é‡æ ¼å¼
        if isinstance(orig_shapes, torch.Tensor):
            orig_shapes = orig_shapes.cpu().numpy().tolist()
        
        # å¤„ç†å•ä¸ªå°ºå¯¸çš„æƒ…å†µ
        if isinstance(orig_shapes, (tuple, list)) and len(orig_shapes) == 2 and isinstance(orig_shapes[0], (int, float)):
            # å•ä¸ªå°ºå¯¸ï¼Œå¤åˆ¶åˆ°æ•´ä¸ªæ‰¹æ¬¡
            return [tuple(orig_shapes)] * batch_size
        
        # å¤„ç†æ‰¹æ¬¡å°ºå¯¸åˆ—è¡¨
        if isinstance(orig_shapes, (list, tuple)):
            result = []
            for i in range(batch_size):
                if i < len(orig_shapes):
                    shape = orig_shapes[i]
                    if isinstance(shape, (list, tuple)) and len(shape) >= 2:
                        result.append(tuple(shape[:2]))  # å–å‰ä¸¤ä¸ªå€¼ä½œä¸º(h,w)
                    else:
                        result.append((640, 640))  # é»˜è®¤å€¼
                else:
                    result.append((640, 640))  # è¶…å‡ºèŒƒå›´ä½¿ç”¨é»˜è®¤å€¼
            return result
        
        # å…¶ä»–æƒ…å†µä½¿ç”¨é»˜è®¤å€¼
        LOGGER.warning(f"æ— æ³•è§£æåŸå§‹å°ºå¯¸æ ¼å¼: {type(orig_shapes)}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        return [(640, 640)] * batch_size
    
    def _filter_labels_for_image(self, labels, bboxes, batch_idx, image_idx):
        """
        ä¼˜åŒ–å•å¼ å›¾åƒçš„æ ‡ç­¾è¿‡æ»¤æ“ä½œã€‚
        
        ä½¿ç”¨å‘é‡åŒ–æ“ä½œæé«˜æ•ˆç‡ï¼Œé¿å…é‡å¤çš„å¼ é‡æ“ä½œã€‚
        
        Args:
            labels: æ‰€æœ‰æ ‡ç­¾
            bboxes: æ‰€æœ‰è¾¹ç•Œæ¡†
            batch_idx: æ‰¹æ¬¡ç´¢å¼•
            image_idx: å½“å‰å›¾åƒç´¢å¼•
            
        Returns:
            tuple: (å½“å‰å›¾åƒæ ‡ç­¾, å½“å‰å›¾åƒè¾¹ç•Œæ¡†)
        """
        if len(batch_idx) > 0 and len(labels) > 0:
            # ä½¿ç”¨å‘é‡åŒ–æ“ä½œè¿‡æ»¤
            mask = (batch_idx == image_idx)
            current_labels = labels[mask] if mask.any() else torch.tensor([])
            current_bboxes = bboxes[mask] if mask.any() and len(bboxes) > 0 else torch.tensor([]).reshape(0, 4)
        else:
            current_labels = labels if len(labels) > 0 else torch.tensor([])
            current_bboxes = bboxes if len(bboxes) > 0 else torch.tensor([]).reshape(0, 4)
        
        # ç¡®ä¿è¿”å›çš„æ˜¯å…‹éš†çš„å¼ é‡ï¼Œé¿å…åç»­ä¿®æ”¹å½±å“åŸå§‹æ•°æ®
        if isinstance(current_labels, torch.Tensor) and current_labels.numel() > 0:
            current_labels = current_labels.clone()
        if isinstance(current_bboxes, torch.Tensor) and current_bboxes.numel() > 0:
            current_bboxes = current_bboxes.clone()
            
        return current_labels, current_bboxes
    
    def init_progress_bar(self):
        """
        åˆå§‹åŒ–éªŒè¯è¿›åº¦æ¡ã€‚
        
        ä»»åŠ¡6.2 - å®ç°è¿›åº¦æ˜¾ç¤ºï¼š
        - æ˜¾ç¤ºéªŒè¯è¿›åº¦æ¡
        - æä¾›å®æ—¶éªŒè¯çŠ¶æ€
        """
        if self.total_batches > 0:
            self.progress_bar = tqdm(
                total=self.total_batches,
                desc="å¤šæ¨¡æ€COCOéªŒè¯",
                unit="batch",
                leave=True,
                ncols=100
            )
            if self.modality:
                self.progress_bar.set_description(f"{self.modality.upper()}æ¨¡æ€COCOéªŒè¯")
            else:
                self.progress_bar.set_description("RGB+Xå¤šæ¨¡æ€COCOéªŒè¯")
    
    def close_progress_bar(self):
        """
        å…³é—­è¿›åº¦æ¡å¹¶æ˜¾ç¤ºå®Œæˆä¿¡æ¯ã€‚
        """
        if self.progress_bar is not None:
            self.progress_bar.close()
            self.progress_bar = None
    
    def finalize_metrics(self):
        """
        å®ŒæˆæŒ‡æ ‡è®¡ç®—ã€‚
        
        é¦–å…ˆè°ƒç”¨çˆ¶ç±»çš„finalize_metricsæ–¹æ³•å®Œæˆæ ‡å‡†æŒ‡æ ‡è®¡ç®—ï¼Œ
        ç„¶åè¿›è¡ŒCOCOæŒ‡æ ‡çš„è®¡ç®—å’Œå¤„ç†ã€‚
        """
        # å…³é—­è¿›åº¦æ¡
        self.close_progress_bar()
        
        # è°ƒç”¨çˆ¶ç±»çš„finalize_metricsæ–¹æ³•
        # è¿™å°†å®Œæˆæ ‡å‡†çš„metricsè®¡ç®—ï¼ŒåŒ…æ‹¬lossã€speedç­‰
        super().finalize_metrics()
        
        # ä»çˆ¶ç±»çš„metricsä¸­æå–å·²å¤„ç†çš„æ•°æ®ç”¨äºCOCOè¯„ä¼°
        if hasattr(self, 'metrics') and hasattr(self.metrics, 'stats') and self.metrics.stats:
            # çˆ¶ç±»çš„statsæ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«å„ç§ç»Ÿè®¡æ•°æ®çš„åˆ—è¡¨
            # æˆ‘ä»¬ç›´æ¥ä½¿ç”¨è¿™äº›æ•°æ®è¿›è¡ŒCOCOè¯„ä¼°
            with tqdm(total=1, desc="è®¡ç®—COCOæŒ‡æ ‡", unit="stage") as pbar:
                self._process_coco_stats_from_metrics()
                pbar.update(1)
        else:
            LOGGER.warning("æ²¡æœ‰å¯ç”¨çš„ç»Ÿè®¡æ•°æ®è¿›è¡ŒCOCOè¯„ä¼°")
            self._set_default_coco_stats()
        
        # ä¿å­˜å¤„ç†çš„å›¾åƒæ•°é‡
        if hasattr(self, 'metrics') and hasattr(self.metrics, 'seen'):
            self.num_images_processed = self.metrics.seen
        else:
            self.num_images_processed = self.seen
        
        # éªŒè¯å®Œæˆï¼Œä¸éœ€è¦é¢å¤–çš„æ—¥å¿—è¾“å‡º
    
    def save_json(self, save_dir=None, filename=None):
        """
        ä»»åŠ¡5.1 - å®ç°JSONæ ¼å¼çš„ç»“æœä¿å­˜ï¼š
        - åœ¨MultiModalCOCOValidatorä¸­å®ç°save_jsonåŠŸèƒ½
        - ä¿å­˜COCOæ ¼å¼çš„éªŒè¯ç»“æœåˆ°JSONæ–‡ä»¶
        - åŒ…å«æ‰€æœ‰è®¡ç®—çš„æŒ‡æ ‡å’Œè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        - æ”¯æŒé€ç±»åˆ«æŒ‡æ ‡çš„ä¿å­˜
        - æ–‡ä»¶å‘½åå’Œè·¯å¾„ä¸ç°æœ‰ç³»ç»Ÿä¿æŒä¸€è‡´
        
        Args:
            save_dir: ä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨self.save_dir
            filename: æ–‡ä»¶åï¼Œé»˜è®¤ä¸ºcoco_results.json
        """
        if self.coco_metrics is None:
            LOGGER.warning("COCOæŒ‡æ ‡å°šæœªè®¡ç®—ï¼Œæ— æ³•ä¿å­˜ç»“æœ")
            return None
        
        # ç¡®å®šä¿å­˜è·¯å¾„
        save_dir = Path(save_dir or self.save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        if filename is None:
            modality_suffix = f"_{self.modality}" if self.modality else "_multimodal" 
            filename = f"coco_results{modality_suffix}.json"
        
        save_path = save_dir / filename
        
        # æ„å»ºå®Œæ•´çš„ç»“æœæ•°æ®
        results_data = {
            "evaluation_info": {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()),
                "validator_type": "MultiModalCOCOValidator",
                "modality": self.modality if self.modality else "RGB+X",
                "dataset": getattr(self.args, 'data', 'N/A'),
                "num_classes": self.nc,
                "num_images": len(self.coco_stats),
                "num_instances": sum(len(stat.get('ground_truth_labels', [])) for stat in self.coco_stats)
            },
            
            "coco_metrics": {
                # ä¸»è¦APæŒ‡æ ‡
                "AP": getattr(self.coco_metrics, 'AP', 0.0),
                "AP50": getattr(self.coco_metrics, 'AP50', 0.0),
                "AP75": getattr(self.coco_metrics, 'AP75', 0.0),
                "APsmall": getattr(self.coco_metrics, 'APsmall', 0.0),
                "APmedium": getattr(self.coco_metrics, 'APmedium', 0.0),
                "APlarge": getattr(self.coco_metrics, 'APlarge', 0.0),
                
                # å¬å›æŒ‡æ ‡
                "AR1": getattr(self.coco_metrics, 'AR1', 0.0),
                "AR10": getattr(self.coco_metrics, 'AR10', 0.0),
                "AR100": getattr(self.coco_metrics, 'AR100', 0.0),
                "ARsmall": getattr(self.coco_metrics, 'ARsmall', 0.0),
                "ARmedium": getattr(self.coco_metrics, 'ARmedium', 0.0),
                "ARlarge": getattr(self.coco_metrics, 'ARlarge', 0.0),
                
                # é™„åŠ æŒ‡æ ‡
                "precision": getattr(self.coco_metrics, 'precision', 0.0),
                "recall": getattr(self.coco_metrics, 'recall', 0.0)
            },
            
            "speed_statistics": {
                "preprocess_ms": self.speed.get('preprocess', 0.0),
                "inference_ms": self.speed.get('inference', 0.0),
                "postprocess_ms": self.speed.get('postprocess', 0.0),
                "total_ms": sum(self.speed.values()),
                "fps": 1000 / np.mean(self.times) if self.times else 0.0,
                "avg_time_per_image_ms": np.mean(self.times) if self.times else 0.0
            },
            
            "detailed_stats": self._get_detailed_stats_for_json(),
            
            "configuration": {
                "args": vars(self.args) if self.args else {},
                "model_info": {
                    "stride": getattr(self, 'stride', None),
                    "nc": self.nc
                }
            }
        }
        
        # æ·»åŠ æ¯ç±»åˆ«æŒ‡æ ‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(self.coco_metrics, 'per_class_metrics') and self.coco_metrics.per_class_metrics:
            class_names = getattr(self.coco_metrics, 'names', {})
            results_data["per_class_metrics"] = {}
            
            for class_id, class_metrics in self.coco_metrics.per_class_metrics.items():
                class_name = class_names.get(class_id, f"class_{class_id}")
                results_data["per_class_metrics"][class_name] = {
                    "AP": class_metrics.get('AP', 0.0),
                    "AP50": class_metrics.get('AP50', 0.0),
                    "AP75": class_metrics.get('AP75', 0.0),
                    "AR100": class_metrics.get('AR100', 0.0)
                }
        
        # ä¿å­˜JSONæ–‡ä»¶
        try:
            with open(save_path, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, indent=2, ensure_ascii=False)
            
            LOGGER.info(f"COCOè¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
            return save_path
            
        except Exception as e:
            LOGGER.error(f"ä¿å­˜COCOç»“æœæ—¶å‡ºé”™: {e}")
            return None
    
    def _get_detailed_stats_for_json(self):
        """
        è·å–ç”¨äºJSONä¿å­˜çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯ã€‚
        
        Returns:
            dict: è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        """
        detailed_stats = {
            "total_predictions": 0,
            "total_ground_truths": 0,
            "images_processed": len(self.coco_stats),
            "processing_details": []
        }
        
        for i, stat in enumerate(self.coco_stats):
            image_detail = {
                "image_id": stat.get('image_id', i),
                "num_predictions": len(stat.get('predictions', [])) if isinstance(stat.get('predictions'), (list, torch.Tensor)) else 0,
                "num_ground_truths": len(stat.get('ground_truth_labels', [])) if isinstance(stat.get('ground_truth_labels'), (list, torch.Tensor)) else 0,
                "original_shape": stat.get('original_shape', (0, 0))
            }
            
            detailed_stats["total_predictions"] += image_detail["num_predictions"]
            detailed_stats["total_ground_truths"] += image_detail["num_ground_truths"]
            detailed_stats["processing_details"].append(image_detail)
        
        return detailed_stats
    
    def save_results(self, save_conf=True, save_json_results=True, plots=True):
        """
        ä»»åŠ¡5.2 - é›†æˆç°æœ‰çš„ä¿å­˜é€‰é¡¹ï¼š
        - æ”¯æŒsave_confå‚æ•°ï¼ˆæ··æ·†çŸ©é˜µä¿å­˜ï¼‰
        - æ”¯æŒplotså‚æ•°ï¼ˆå¯è§†åŒ–å›¾è¡¨ç”Ÿæˆï¼‰
        - ç¡®ä¿ä¸çˆ¶ç±»MultiModalDetectionValidatorä¿å­˜åŠŸèƒ½çš„å…¼å®¹
        - ç»§æ‰¿å¹¶æ‰©å±•ç°æœ‰çš„ä¿å­˜æµç¨‹
        - æ”¯æŒæ‰€æœ‰ç°æœ‰çš„å¯è§†åŒ–é€‰é¡¹
        
        Args:
            save_conf: æ˜¯å¦ä¿å­˜æ··æ·†çŸ©é˜µ
            save_json_results: æ˜¯å¦ä¿å­˜JSONæ ¼å¼ç»“æœ
            plots: æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        """
        save_dir = Path(self.save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        LOGGER.info(f"å¼€å§‹ä¿å­˜COCOéªŒè¯ç»“æœåˆ°: {save_dir}")
        
        results_saved = []
        
        # 1. ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†ç»“æœ
        if save_json_results:
            try:
                json_path = self.save_json(save_dir)
                if json_path:
                    results_saved.append(f"JSONç»“æœ: {json_path}")
            except Exception as e:
                LOGGER.error(f"ä¿å­˜JSONç»“æœå¤±è´¥: {e}")
        
        # 2. ä¿å­˜æ··æ·†çŸ©é˜µï¼ˆå¦‚æœæ”¯æŒï¼‰
        if save_conf and hasattr(self.coco_metrics, 'confusion_matrix'):
            try:
                conf_path = save_dir / "confusion_matrix.png"
                if hasattr(self.coco_metrics.confusion_matrix, 'plot'):
                    self.coco_metrics.confusion_matrix.plot(save_dir=save_dir, names=getattr(self.coco_metrics, 'names', {}))
                    results_saved.append(f"æ··æ·†çŸ©é˜µ: {conf_path}")
            except Exception as e:
                LOGGER.warning(f"ä¿å­˜æ··æ·†çŸ©é˜µå¤±è´¥: {e}")
        
        # 3. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        if plots:
            try:
                self._save_visualization_plots(save_dir)
                results_saved.append(f"å¯è§†åŒ–å›¾è¡¨: {save_dir / 'plots'}")
            except Exception as e:
                LOGGER.warning(f"ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")
        
        # 4. ä¿å­˜æ±‡æ€»æŠ¥å‘Š
        try:
            self._save_summary_report(save_dir)
            results_saved.append(f"æ±‡æ€»æŠ¥å‘Š: {save_dir / 'coco_summary.txt'}")
        except Exception as e:
            LOGGER.warning(f"ä¿å­˜æ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")
        
        # 5. è°ƒç”¨çˆ¶ç±»ä¿å­˜æ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ä¸”å…¼å®¹ï¼‰
        try:
            if hasattr(super(), 'save_results'):
                # è°ƒç”¨çˆ¶ç±»æ–¹æ³•ï¼Œä½†è¦å¤„ç†å‚æ•°å…¼å®¹æ€§
                super_args = {}
                if 'save_conf' in super().save_results.__code__.co_varnames:
                    super_args['save_conf'] = save_conf
                if 'plots' in super().save_results.__code__.co_varnames:
                    super_args['plots'] = plots
                
                super().save_results(**super_args)
        except Exception as e:
            LOGGER.warning(f"è°ƒç”¨çˆ¶ç±»ä¿å­˜æ–¹æ³•å¤±è´¥: {e}")
        
        # è¾“å‡ºä¿å­˜ç»“æœæ€»ç»“
        if results_saved:
            LOGGER.info("ä¿å­˜çš„ç»“æœæ–‡ä»¶:")
            for result in results_saved:
                LOGGER.info(f"  - {result}")
        else:
            LOGGER.warning("æœªä¿å­˜ä»»ä½•ç»“æœæ–‡ä»¶")
        
        return save_dir
    
    def _save_visualization_plots(self, save_dir):
        """
        ä¿å­˜å¯è§†åŒ–å›¾è¡¨ã€‚
        
        Args:
            save_dir: ä¿å­˜ç›®å½•
        """
        plots_dir = save_dir / "plots"
        plots_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. COCOæŒ‡æ ‡å¯¹æ¯”å›¾
        self._plot_coco_metrics_comparison(plots_dir)
        
        # 2. é€Ÿåº¦ç»Ÿè®¡å›¾
        self._plot_speed_statistics(plots_dir)
        
        # 3. å¦‚æœcoco_metricsæ”¯æŒç»˜å›¾ï¼Œè°ƒç”¨å…¶æ–¹æ³•
        if hasattr(self.coco_metrics, 'plot') and callable(self.coco_metrics.plot):
            try:
                self.coco_metrics.plot(save_dir=plots_dir)
            except Exception as e:
                LOGGER.warning(f"COCOMetricsç»˜å›¾å¤±è´¥: {e}")
    
    def _plot_coco_metrics_comparison(self, save_dir):
        """
        ç»˜åˆ¶COCOæŒ‡æ ‡å¯¹æ¯”å›¾ã€‚
        """
        try:
            import matplotlib.pyplot as plt
            
            # APæŒ‡æ ‡
            ap_metrics = ['AP', 'AP50', 'AP75', 'APsmall', 'APmedium', 'APlarge']
            ap_values = [getattr(self.coco_metrics, metric, 0.0) for metric in ap_metrics]
            
            # ARæŒ‡æ ‡  
            ar_metrics = ['AR1', 'AR10', 'AR100', 'ARsmall', 'ARmedium', 'ARlarge']
            ar_values = [getattr(self.coco_metrics, metric, 0.0) for metric in ar_metrics]
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # APæŒ‡æ ‡å›¾
            ax1.bar(ap_metrics, ap_values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b'])
            ax1.set_title('COCO Average Precision (AP) Metrics')
            ax1.set_ylabel('Score')
            ax1.set_ylim(0, 1)
            ax1.tick_params(axis='x', rotation=45)
            
            # ARæŒ‡æ ‡å›¾
            ax2.bar(ar_metrics, ar_values, color=['#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#1f77b4', '#ff7f0e'])
            ax2.set_title('COCO Average Recall (AR) Metrics')
            ax2.set_ylabel('Score')
            ax2.set_ylim(0, 1)
            ax2.tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            plt.savefig(save_dir / 'coco_metrics_comparison.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except ImportError:
            LOGGER.warning("matplotlibæœªå®‰è£…ï¼Œè·³è¿‡COCOæŒ‡æ ‡å¯¹æ¯”å›¾ç”Ÿæˆ")
        except Exception as e:
            LOGGER.warning(f"ç”ŸæˆCOCOæŒ‡æ ‡å¯¹æ¯”å›¾å¤±è´¥: {e}")
    
    def _plot_speed_statistics(self, save_dir):
        """
        ç»˜åˆ¶é€Ÿåº¦ç»Ÿè®¡å›¾ã€‚
        """
        try:
            import matplotlib.pyplot as plt
            
            if not any(self.speed.values()):
                return
            
            stages = list(self.speed.keys())
            times = list(self.speed.values())
            
            plt.figure(figsize=(10, 6))
            bars = plt.bar(stages, times, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
            plt.title('Processing Speed Statistics')
            plt.ylabel('Time (ms)')
            plt.xlabel('Processing Stage')
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, time_val in zip(bars, times):
                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
                        f'{time_val:.1f}ms', ha='center', va='bottom')
            
            plt.tight_layout()
            plt.savefig(save_dir / 'speed_statistics.png', dpi=300, bbox_inches='tight')
            plt.close()
            
        except ImportError:
            LOGGER.warning("matplotlibæœªå®‰è£…ï¼Œè·³è¿‡é€Ÿåº¦ç»Ÿè®¡å›¾ç”Ÿæˆ")
        except Exception as e:
            LOGGER.warning(f"ç”Ÿæˆé€Ÿåº¦ç»Ÿè®¡å›¾å¤±è´¥: {e}")
    
    def _save_summary_report(self, save_dir):
        """
        ä¿å­˜æ–‡æœ¬æ ¼å¼çš„æ±‡æ€»æŠ¥å‘Šã€‚
        
        Args:
            save_dir: ä¿å­˜ç›®å½•
        """
        report_path = save_dir / "coco_summary.txt"
        
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("å¤šæ¨¡æ€COCOè¯„ä¼°æ±‡æ€»æŠ¥å‘Š\n")
                f.write("=" * 80 + "\n\n")
                
                # åŸºæœ¬ä¿¡æ¯
                f.write(f"è¯„ä¼°æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime())}\n")
                f.write(f"éªŒè¯å™¨ç±»å‹: MultiModalCOCOValidator\n")
                f.write(f"éªŒè¯æ¨¡å¼: {self.modality if self.modality else 'RGB+X'}\n")
                f.write(f"æ•°æ®é›†: {getattr(self.args, 'data', 'N/A')}\n")
                f.write(f"ç±»åˆ«æ•°: {self.nc}\n")
                f.write(f"éªŒè¯å›¾åƒæ•°: {len(self.coco_stats)}\n\n")
                
                # ä¸»è¦æŒ‡æ ‡
                f.write("ä¸»è¦COCOæŒ‡æ ‡:\n")
                f.write("-" * 40 + "\n")
                f.write(f"mAP@0.5:0.95:  {getattr(self.coco_metrics, 'AP', 0.0):.3f}\n")
                f.write(f"mAP@0.5:      {getattr(self.coco_metrics, 'AP50', 0.0):.3f}\n")
                f.write(f"mAP@0.75:     {getattr(self.coco_metrics, 'AP75', 0.0):.3f}\n\n")
                
                # å°ºå¯¸åˆ†åˆ«æŒ‡æ ‡
                f.write("ä¸åŒå°ºå¯¸ç›®æ ‡æŒ‡æ ‡:\n")
                f.write("-" * 40 + "\n")
                f.write(f"APsmall:      {getattr(self.coco_metrics, 'APsmall', 0.0):.3f}\n")
                f.write(f"APmedium:     {getattr(self.coco_metrics, 'APmedium', 0.0):.3f}\n")
                f.write(f"APlarge:      {getattr(self.coco_metrics, 'APlarge', 0.0):.3f}\n\n")
                
                # å¬å›æŒ‡æ ‡
                f.write("å¬å›æŒ‡æ ‡:\n")
                f.write("-" * 40 + "\n")
                f.write(f"AR1:          {getattr(self.coco_metrics, 'AR1', 0.0):.3f}\n")
                f.write(f"AR10:         {getattr(self.coco_metrics, 'AR10', 0.0):.3f}\n")
                f.write(f"AR100:        {getattr(self.coco_metrics, 'AR100', 0.0):.3f}\n\n")
                
                # é€Ÿåº¦ç»Ÿè®¡
                if any(self.speed.values()):
                    f.write("é€Ÿåº¦ç»Ÿè®¡:\n")
                    f.write("-" * 40 + "\n")
                    f.write(f"é¢„å¤„ç†:       {self.speed.get('preprocess', 0.0):.1f}ms\n")
                    f.write(f"æ¨ç†:         {self.speed.get('inference', 0.0):.1f}ms\n")
                    f.write(f"åå¤„ç†:       {self.speed.get('postprocess', 0.0):.1f}ms\n")
                    if self.times:
                        avg_time = np.mean(self.times)
                        f.write(f"å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.1f}ms/å›¾åƒ\n")
                        f.write(f"å¤„ç†é€Ÿåº¦:     {1000/avg_time:.1f} FPS\n")
                
                f.write("\n" + "=" * 80 + "\n")
                
        except Exception as e:
            LOGGER.error(f"ä¿å­˜æ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")
    
    def __enter__(self):
        """
        ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£ï¼Œåˆå§‹åŒ–è¿›åº¦æ¡ã€‚
        """
        self.init_progress_bar()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """
        ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£ï¼Œæ¸…ç†è¿›åº¦æ¡ã€‚
        """
        self.close_progress_bar()
        return False